{"config":{"lang":["en"],"separator":"[\\s\\-\\.\\_]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Term 3 Notes 2021","text":""},{"location":"ddw/deadlines/","title":"Important Deadlines","text":"<p>1D Mini pt2 W6 Friday 22th Oct Reading Quiz - Monday 9 AM</p>"},{"location":"ddw/notes/","title":"Notes","text":""},{"location":"ddw/to_know/","title":"Important Information","text":""},{"location":"hass/deadlines/","title":"Important Deadlines","text":"<p>Mid term essay by Week 8 Final research essay by Week 13</p>"},{"location":"hass/notes/","title":"Notes","text":""},{"location":"hass/to_know/","title":"Important Information","text":""},{"location":"maths/deadlines/","title":"Important Deadlines","text":"<p>HW2 - Friday W5 15<sup>th</sup> Oct 5 PM</p>"},{"location":"maths/notes/","title":"Notes","text":""},{"location":"maths/notes/#definitions","title":"Definitions","text":"<p>Probability: Mathematical method to quantify the chance of something happening by using a # b/n 0-1.</p> <p>Statistics: sci of collecting, analysing and interpreting data in order to extract meaningful info and conclusions</p> <p>Population: collection of all individual items of a particular type</p> <p>Sample: a sub collection of pop chosen by some rule</p>"},{"location":"maths/notes/#types-of-statistical-studies","title":"Types of statistical studies","text":"<ol> <li>Comparitive (b/n &gt;= 2 grps), non comparitive (learn more about 1 grp)</li> <li>Observational (no intervention) vs Experimental (control)</li> </ol> <p>Sampling errors: every survey suffers from errors called sampling errors because it can't be done over the full pop. (eg. selection bias)</p> <p>Systematic errorss: zero error etc.</p> <p>Random errors: single event effects</p>"},{"location":"maths/notes/#types-of-data","title":"Types of data","text":"<ol> <li> <p>Categorical (qualitative): repr-ed with freq. tables, bar graphs</p> <p>1.1 Nominal (fav. colour: red, green, blue, no ranking)</p> <p>1.2 Ordinal (disagree, neutral, agree, ranked)</p> </li> <li> <p>Numerical (quantitative): histograms</p> <p>2.1 Discrete (numbers, counting things, ints)</p> <p>2.2 Continuous (measurements taken over time, speed, etc.)</p> </li> </ol>"},{"location":"maths/notes/#measures-of-centre-central-tendency","title":"Measures of Centre, Central Tendency","text":"<ol> <li>Mean \\(\\bar{x}\\) (not robust, sensitive to small/large vals)</li> <li>Median \\(\\tilde{x}\\) (robust, not sensitive to small/large vals)</li> <li>Mode - Unimodal, Bimodal.</li> </ol> <p>Symmetric unimodal graph =&gt; mean, median and mode are all coincident</p> <p>Skewed bimodal graph =&gt; if the tail of the graph is to left, skewed left, if tial to right, skewed right. (skew is opp of peak!)</p>"},{"location":"maths/notes/#measures-of-spread","title":"Measures of spread","text":"<p>Units are important when calc-ing these.</p> <p>Variance \\(\\sigma^2 = S^2_x = \\cfrac{1}{n-1} \\sum\\limits_{i=1}^n (x_i - \\bar{x})^2\\) (unit^2)</p> <p>Standard deviation \\(\\sigma = \\sqrt{S^2_x}\\) (unit) (not robust)</p> <p>Range \\(x_{max} - x_{min}\\) (unit)</p> <p>Interquartile Range (IQR) \\(IQR = Q_3 - Q_1\\) where \\(Q_1\\) is the median of the lower half and \\(Q_3\\) is the median of the upper half If the # of entries is odd, discard the overall median before dividing in half. (unit) There is no generlly accepted definition for IQR, make your own usage and definition clear as per use case</p> <p>5 Number summary: \\(x_{min}\\), \\(Q_{1}\\), \\(\\tilde{x}\\), \\(Q_3\\), \\(x_{max}\\) Used to draw box plot. <code>QUARTILE.INC(range, 0-4)</code> in XL</p> <p>Outliers: values very far from the bulk of the data. There is no set defn for these, just if a value is 1.5IQR less than \\(Q_1\\) or 1.5IQR more than \\(Q_3\\) then it is generally regarded as an outlier</p>"},{"location":"maths/notes/#moving-average","title":"Moving average","text":"<p>\\(m_n = \\cfrac{\\sum\\limits_{i=1}^{k} (y_{n-i})}{k}\\)</p> <p>Trendline in XL.</p>"},{"location":"maths/notes/#bivariate-data","title":"Bivariate Data","text":"<p>Data involving \\((x_i, y_i)\\) indep &amp; dep vars. All single series terms can be used on either series</p>"},{"location":"maths/notes/#covariance-and-correlation","title":"Covariance and Correlation","text":"<p>For population: \\(S_{xy} = \\cfrac{1}{n} \\sum\\limits_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})\\) (unit^2)</p> <p>For sample: \\(S_{xy} = \\cfrac{1}{n-1} \\sum\\limits_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})\\) (unit^2)</p> <p>\\(r_{xy} = \\cfrac{S_{xy}}{S_x S_y}\\)</p> <p><code>COVARIANCE.S</code> and <code>CORREL</code> in XL</p>"},{"location":"maths/notes/#linear-regression","title":"Linear Regression","text":"<p>\\(x\\) - predictor/explanatory/independent variable \\(y\\) - response/outcome/dependent variable</p>"},{"location":"maths/notes/#least-squares-method","title":"Least Squares Method","text":"<p>Assuming that there is a line of best fit for the linear data, \\(y = \\beta_1 x_i + \\beta_0\\)</p> <p>We compute the signed distance of all the \\(y_i\\) values with the predicted values from the above equation, and minimise it using mvc to find the most apt values of \\(\\beta_0\\) and \\(\\beta_1\\)</p> <p>\\(Q = \\sum\\limits_{i=1}^{n}[ y_i - (\\beta_1 x_i + \\beta_0)]^2\\)</p>"},{"location":"maths/notes/#derivation-using-mvc","title":"Derivation Using MVC:","text":"<p>\\(\\cfrac{\\partial Q}{ \\partial \\beta_1} = \\sum\\limits_{i=1}^{n} - 2 x_i [ y_i - (\\beta_1 x_i + \\beta_0)]\\)</p> <p>\\(\\cfrac{\\partial Q}{ \\partial \\beta_0} = \\sum\\limits_{i=1}^{n} - 2 [ y_i - (\\beta_1 x_i + \\beta_0)]\\)</p> <p>Equating to 0</p> <p>\\(\\sum\\limits_{i=1}^{n} - 2 x_i [ y_i - (\\beta_1 x_i + \\beta_0)] = 0\\)</p> <p>\\(\\sum\\limits_{i=1}^{n} - 2 [ y_i - (\\beta_1 x_i + \\beta_0)] = 0\\)</p> <p>divide by -2 =&gt;</p> <p>\\(\\sum\\limits_{i=1}^{n}x_i[ y_i - (\\beta_1 x_i + \\beta_0)] = 0\\)</p> <p>\\(\\sum\\limits_{i=1}^{n}[y_i - (\\beta_1 x_i + \\beta_0)] = 0\\)</p> <p>=&gt;</p> <p>\\(\\sum\\limits_{i=1}^{n} x_i y_i - \\sum\\limits_{i=1}^{n}x_i(\\beta_1 x_i + \\beta_0) = 0\\)</p> <p>\\(\\sum\\limits_{i=1}^{n} y_i - \\sum\\limits_{i=1}^{n}(\\beta_1 x_i + \\beta_0) = 0\\)</p> <p>=&gt;</p> <p>\\(\\sum\\limits_{i=1}^{n} x_i y_i - \\beta_1\\sum\\limits_{i=1}^{n} x^2_i + \\beta_0 \\sum\\limits_{i=1}^{n} x_i = 0\\) ... (i)</p> <p>\\(\\sum\\limits_{i=1}^{n} y_i - \\beta_1 \\sum\\limits_{i=1}^{n} x_i + n\\beta_0 = 0\\) ... (ii)</p> <p>Multiply (ii) by \\(\\bar{x}\\) =&gt;</p> <p>\\(\\sum\\limits_{i=1}^{n} x_i y_i - \\beta_1\\sum\\limits_{i=1}^{n} x^2_i +  n \\bar{x} \\beta_0 = 0\\)</p> <p>\\(n \\bar{y} \\bar{x} - \\beta_1 n \\bar{x}^2 + n \\bar{x} \\beta_0 = 0\\) ... (iii)</p> <p>subtract (i) from (ii) =&gt;</p> <p>\\(n \\bar{y} \\bar{x} - \\sum\\limits_{i=1}^{n} x_i y_i + \\beta_1 (\\sum\\limits_{i=1}^{n}x^2_i - n \\bar{x}^2) = 0\\)</p> <p>=&gt;</p> <p>\\(\\beta_1 = \\cfrac{n \\bar{y} \\bar{x} - \\sum\\limits_{i=1}^{n} x_i y_i}{n \\bar{x}^2 - \\sum\\limits_{i=1}^{n}x^2_i}\\)</p>"},{"location":"maths/notes/#final-result","title":"Final Result","text":"<p>INSERT_ALGEBRA_HERE W2C1S30</p> <p>\\(\\beta_1 = \\cfrac{S_{xy}}{S_{x}^2}\\)</p> <p>INSERT_ALGEBRA_HERE</p> <p>\\(\\beta_0 = \\bar{y} - \\bar{x}\\beta_1\\)</p> <p>Since  = \\(\\hat{\\beta_1}\\) and \\(\\hat{\\beta_0}\\) are estimaters of their values for the \"true\" linear relation, they are denoted by the hat notation.</p>"},{"location":"maths/notes/#coefficient-of-determination","title":"Coefficient of Determination","text":"<p>This is a measure of how successful the regression model is.</p> <p>\\(r^2 = \\cfrac{\\sum\\limits_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2}{\\sum\\limits_{i=1}^{n} (y_i - \\bar{y})^2}\\)</p> <p>0 implies complete failure and 1 implies complete fit</p> <p>\\(r^2 = r_{xy}^2 = \\cfrac{S_{xy}^2}{S_x^2 S_y^2}\\)</p>"},{"location":"maths/notes/#multiple-regression-with-matricies","title":"Multiple regression with matricies","text":"<p>\\(y = X \\beta\\)</p> <p>Here, \\(X\\) is an \\(n\\times k\\) matrix of \\(k\\) independent variables in \\(n\\) rows</p> <p>\\(\\beta\\) is an \\(k \\times 1\\) matrix of \\(k\\) coefficients for the \\(k\\) independent variables</p> <p>\\(Q = ||y - X\\beta||^2\\)</p> <p>INSERT_ALGEBRA_FOR_SOLUTION W2C1S30</p> <p>\\(\\hat{\\beta} = (X^T X)^{-1}X^T y\\)</p> <p>CoD formula is the same</p>"},{"location":"maths/notes/#overfitting","title":"Overfitting","text":"<p>increasing the order of regression too much hurts the model in the long run</p>"},{"location":"maths/notes/#axioms-of-probability","title":"Axioms of Probability","text":"<ol> <li>\\(\\mathbb{P}(E) \\geq 0\\) The probability of any event is non negative</li> <li>\\(\\mathbb{P}(S) = 1\\) or \\(\\mathbb{P}(\\phi) = 0\\) The probability of an event from the sample space occuring is always one</li> <li>if \\(E_i \\cap E_j = \\phi\\) then \\(E_i + E_j = E_i \\cup E_j\\)</li> </ol>"},{"location":"maths/notes/#bayes-theorem-conditional-probability-and-independent-events","title":"Baye's Theorem, Conditional Probability and Independent events","text":""},{"location":"maths/notes/#random-variables","title":"Random Variables","text":"<p>A random variable is a function on the sample space of an experiment. It maps each outcome of the experiment to some \\(\\mathbb{R}\\) value</p> <p>Remember for the functions below, \\(x \\in \\mathbb{R}\\)</p>"},{"location":"maths/notes/#probability-mass-function-pmf","title":"Probability Mass Function (pmf)","text":"<p>For a discrete random variable:</p> <p>\\(f(x) = \\mathbb{P}(X = x)\\)</p>"},{"location":"maths/notes/#cumulative-distribution-function-cdf","title":"Cumulative Distribution Function (cdf)","text":"<p>For a discrete random variable:</p> <p>\\(F(x) = \\mathbb{P}(X \\leq x_n) =  \\sum\\limits_{i=1}^{n} f(x_i)\\)</p>"},{"location":"maths/notes/#geometric-random-variables","title":"Geometric Random Variables","text":"<p># of coin tosses till T for the first time</p> <p>\\(X \\sim geometric(p)\\)</p>"},{"location":"maths/notes/#memorylessness-property-of-geometric-distributions","title":"Memorylessness property of geometric Distributions","text":"<p>\\(\\mathbb{P}(X \\geq s + t | X \\geq t) = \\mathbb{P}(X \\geq s)\\)</p>"},{"location":"maths/notes/#expectation-mean-and-variance","title":"Expectation, Mean and variance","text":""},{"location":"maths/notes/#expectation","title":"Expectation","text":"<p>\\(\\bar{x} = \\sum\\limits_{i=1}^{n} x_i \\cfrac{|E_i|}{|S|}\\)</p> <p>\\(\\bar{x} = \\sum\\limits_{i=1}^{n} x_i \\mathbb{P}(X = x_i)\\)</p> <p>This is the expeced value:</p> <p>\\(\\mathbb{E}(x) = \\sum\\limits_{i=0}^{n} x_i \\mathbb{P}(X = x_i)\\)</p>"},{"location":"maths/notes/#variance","title":"Variance","text":"<p>\\(Var(X) = \\sum\\limits_{i=0}^{n} \\mathbb{P}(x)(\\mathbb{E}(x) - x_i)^2\\)</p>"},{"location":"maths/notes/#distributions-of-random-variables","title":"Distributions of Random Variables","text":""},{"location":"maths/notes/#binomial-distributions","title":"Binomial Distributions","text":"<p>If an experiment has two outcomes with probabilities \\(\\mathbb{P}(A) = p\\) and \\(\\mathbb{P}(A') = 1 - p\\)</p> <p>If X is the number of times the outcome was A, then X is a binomial distribution denoted by \\(X \\sim binomial(n, p)\\)</p> <p>pmf: \\(\\mathbb{P}(X = k) = f(x) = \\displaystyle\\binom{n}{k}p^k(1-p)^{n-k}\\)</p>"},{"location":"maths/notes/#mean-variance-of-a-binomial-distribution","title":"Mean &amp; Variance of a Binomial Distribution","text":"<p>\\(\\mathbb{E}(x) = np\\)</p> <p>\\(Var(x) = np(1-p)\\)</p>"},{"location":"maths/notes/#poisson-distribution","title":"Poisson Distribution","text":"<p>A random variable \\(X\\) satisfies a Poisson distribution if its pmf is a function of a value \\(\\lambda &gt; 0\\) such that:</p> <p>\\(\\mathbb{P}(X = k) =  e^{-\\lambda}\\cfrac{\\lambda^k}{k!}, k \\in 0, 1, 2 ...\\)</p> <p>\\(\\mathbb{E}(x) = \\lambda\\)</p> <p>\\(Var(x) = \\lambda\\)</p> <p>when \\(\\lambda = np\\), it approximates a binomial distribution with parameters \\(n\\), \\(p\\)</p>"},{"location":"maths/notes/#properties-of-expectation-and-variance","title":"Properties of Expectation and Variance","text":"<p>\\(\\mathbb{E}(g(X)) = \\sum\\limits_{i=1}^{n}g(x_i)\\mathbb{P}(X = x_i)\\)</p> <p>\\(Var(X) = \\mathbb{E}(X^2) - \\mathbb{E}(X)^2\\)</p> <p>\\(Var(aX + b) = a^2 Var(X)\\)</p> <p>\\(\\mathbb{E}(\\sum\\limits_{i=1}^{m}X_i) = \\sum\\limits_{i=1}^{m}\\mathbb{E}(X_i)\\)</p>"},{"location":"maths/notes/#bernoulli-distributions","title":"Bernoulli Distributions","text":"<p>A random variable is a Bernoulli random variable if it can only take on values 1 (success) and 0 (faliure)</p> <p>\\(\\mathbb{P}(X = 1) = p \\;\\;\\;\\; \\mathbb{P}(X = 0) = 1 - p\\)</p> <p>\\(\\mathbb{E}(X) = p \\;\\;\\;\\; Var(X) = p(1 - p)\\)</p> <p>Usually, a complex random variable may be represented as a sum of suitably chosen bernoulli variables</p>"},{"location":"maths/notes/#probability-with-continuous-random-variables","title":"Probability with Continuous Random Variables","text":"<p>\\(f : \\mathbb{R} \\rightarrow [0, \\infty)\\) is called the probability density function (pdf) of X if for any \\(A \\in \\mathbb{R}\\)</p> \\[\\mathbb{P}(X \\in A) = \\int_{A}f(x)dx\\] <p>The cumulative density function (cdf) of X is defined as:</p> \\[F(x) = \\mathbb{P}(X \\leq x) = \\int\\limits_{-\\infty}^{x}f(t)dt\\] <p>\\(F'(x) = f(x)\\) It is often easier to find the cdf and then differentiate for the pdf.</p>"},{"location":"maths/notes/#properties-of-the-cdf","title":"Properties of the CDF","text":"<ol> <li>\\(F(x)\\) is a non decreasing function</li> <li>\\(0 \\leq F(x) \\leq 1\\); \\(\\lim\\limits_{x \\rightarrow -\\infty} F(x) = 0\\); \\(\\lim\\limits_{x \\rightarrow \\infty} F(x) = 1\\)</li> <li>\\(F(x)\\) represents a probability</li> <li>For \\(a \\leq b\\), \\(\\mathbb{P}(a \\leq X \\leq b) = F(b) - F(a)\\)</li> </ol>"},{"location":"maths/notes/#properties-of-the-pdf","title":"Properties of the PDF","text":"<p>\\(f(x)\\) does not represent a probability by itself, only for a small \\(\\delta x\\)</p> <p>\\(f(x)\\delta x \\approx \\mathbb{P}(x \\leq X \\leq x + \\delta x)\\)</p> <ol> <li>\\(\\mathbb{P}(a \\leq X \\leq b) = \\int\\limits_a^b f(x)dx = F(b) - F(a)\\)</li> <li>\\(\\mathbb{P}(X \\in \\mathbb{R}) = \\int\\limits_{-\\infty}^{\\infty} f(x)dx = 1\\)</li> <li>\\(\\mathbb{P}(X = a) = \\int\\limits_{a}^{a} f(x)dx = 0\\)</li> </ol> <p>This is why \\(\\leq\\) and \\(&lt;\\) are interchange-able</p>"},{"location":"maths/notes/#expectation-of-continuous-distribution","title":"Expectation of Continuous Distribution","text":"\\[ \\mu = \\mathbb{E}(X) = \\int\\limits_{-\\infty}^{\\infty} x f(x) dx \\] <p>All properties for expectation hold Here</p> <p>\\(\\mathbb{E}(g(X)) = \\int\\limits_{-\\infty}^{\\infty}g(x_i)f(x)dx\\)</p> <p>\\(Var(X) = \\mathbb{E}(X^2) - \\mathbb{E}(X)^2\\)</p> <p>\\(Var(aX + b) = a^2 Var(X)\\)</p> <p>\\(\\mathbb{E}(\\sum\\limits_{i=1}^{m}X_i) = \\sum\\limits_{i=1}^{m}\\mathbb{E}(X_i)\\)</p>"},{"location":"maths/notes/#uniform-distribution","title":"Uniform Distribution","text":"<p>A cont. rand. dist. X is uniform if</p> \\[  f(x) =      \\begin{cases}         0 &amp; x &lt; a \\\\         \\cfrac{1}{b-a} &amp; a \\leq x \\leq b \\\\         0 &amp; b &lt; x     \\end{cases} \\] \\[  F(x) =      \\begin{cases}         0 &amp; x &lt; a \\\\         \\cfrac{x-a}{b-a} &amp; a \\leq x \\leq b \\\\         1 &amp; b &lt; x     \\end{cases} \\] <p>\\(X \\sim uniform(a, b)\\)</p>"},{"location":"maths/notes/#expectation-of-uniform-distribution","title":"Expectation of Uniform Distribution","text":"<p>\\(\\mathbb{E}(X) = \\cfrac{a+b}{2}\\)</p>"},{"location":"maths/notes/#variance-of-distribution","title":"Variance of Distribution","text":"<p>\\(Var(X) = \\cfrac{(b-a)^2}{12}\\)</p>"},{"location":"maths/notes/#exponential-distribution","title":"Exponential Distribution","text":"\\[  f(x) =      \\begin{cases}         \\lambda e^{-\\lambda x} &amp; x \\geq 0 \\\\         0 &amp; x &lt; 0     \\end{cases} \\] <p>\\(X \\sim exponential(\\lambda)\\)</p> \\[  F(x) =      \\begin{cases}         1 - e^{-\\lambda x} &amp; x \\geq 0 \\\\         0 &amp; x &lt; 0     \\end{cases} \\] <p>\\(\\lambda\\) - Rate of average occurrance</p>"},{"location":"maths/notes/#memorylessness-property-of-exp-distributions","title":"Memorylessness property of exp Distributions","text":"<p>\\(\\mathbb{P}(X \\geq s + t | X \\geq t) = \\mathbb{P}(X \\geq s)\\)</p>"},{"location":"maths/notes/#expectation-of-exp-distribution","title":"Expectation of exp distribution","text":"<p>\\(\\mathbb{E}(X) = \\cfrac{1}{\\lambda}\\)</p>"},{"location":"maths/notes/#variance-of-exp-distribution","title":"Variance of exp distribution","text":"<p>\\(Var(X) = \\cfrac{1}{\\lambda^2}\\)</p>"},{"location":"maths/notes/#expectation-of-a-crv-whoes-pdf-0-for-x-0","title":"Expectation of a CRV Whoes PDF = 0 for X &lt; 0","text":"\\[\\mathbb{E}(X) = \\int\\limits_{0}^{\\infty}(1-F(x))dx\\]"},{"location":"maths/notes/#standard-normal-distribution-aka-gaussian-distribution","title":"Standard Normal Distribution (aka Gaussian Distribution)","text":"<p>A rand. var. \\(Z\\) is said to satisfy standard normal dist. if its pdf is given by:</p> \\[ \\phi(x) = \\cfrac{1}{\\sqrt{2\\pi}} e^{-x^2/2}, x \\in \\mathbb{R} \\] <p>Using double integration it can be shown that this is a valid cdf</p> <p>SND is so common \\(Z\\) is used to denote it. its cdf is given by the following integral which does not have an elementary anti-derivative</p> \\[ \\Phi(x) = \\cfrac{1}{\\sqrt{2\\pi}} \\int\\limits_{-\\infty}^{x} e^{-t^2/2} dt \\] <p>\\(\\mathbb{E}(Z) = 0\\) and \\(Var(Z) = 1\\)</p>"},{"location":"maths/notes/#general-normal-distribution","title":"General Normal Distribution","text":"<p>if \\(X = aZ + b\\), we can find the cdf as follows</p> \\[ F(x) = \\mathbb{P}(aZ + b \\leq x) = \\mathbb{P}(Z \\leq \\cfrac{x - b}{a}) = \\Phi(\\cfrac{x - b}{a}) \\] <p>On differentiating, we find that</p> \\[ f(x) = \\cfrac{1}{\\sqrt{2a^2\\pi}} e^{-(x-b)^2/(2a^2)} \\] <p>The expectation and variance of the pdf are as follows:</p> <p>\\(\\mathbb{E}(X) = b\\)</p> <p>\\(Var(X) = a^2\\)</p> <p>replacing \\(b\\) with \\(\\mu\\) and \\(a\\) with \\(\\sigma\\)</p> \\[ f(x) = \\cfrac{1}{\\sqrt{2\\sigma^2\\pi}} e^{-(x-\\mu)^2/(2\\sigma^2)} \\] <p>This is formally known as a normal distribution \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\). Here, \\(\\mathbb{E}(X) = \\mu\\) and \\(Var(X) = \\sigma^2\\)</p> <p>\\(Z ~ \\mathcal{N}(0, 1) is the SND\\)</p>"},{"location":"maths/notes/#properties-of-gnd","title":"Properties of GND","text":"<ol> <li>The probability of a value being within \\(k\\) standard deviations of the mean is the same for every GND</li> </ol> <p>\\(\\color{cyan}\\mathbb{P}(\\mu - k\\sigma \\leq X \\leq \\mu + k\\sigma) \\color{white}= \\color{lime}\\mathbb{P}(-k\\leq \\cfrac{X - \\mu}{\\sigma} \\leq k) \\color{white}= \\color{yellow}\\mathbb{P}(-k\\leq Z \\leq k)\\)</p> <p>\\(\\color{cyan}\\mathbb{P}(-k \\leq Z \\leq k) \\color{white}= \\color{lime}\\Phi(k) - \\Phi(-k) \\color{white}= \\color{yellow}2\\Phi(k) - 1 \\color{white}= 1 - 2\\Phi(-k)\\)</p>"},{"location":"maths/notes/#approximating-binomial-dist-with-gn-dist","title":"Approximating Binomial Dist with GN Dist","text":"<p>\\(X \\sim binomial(n, p)\\) has an \\(\\mathbb{E}(X) = np\\) and \\(Var(X) = np(1-p)\\).</p> <p>Note that the value \\(\\mathbb{P}(X = K)\\) is the area of the rectangle from \\(k - 0.5\\) to \\(k + 0.5\\) on the binomial dist.</p> <p>This can be thus be approximated by \\(\\mathbb{P}(k+0.5 \\leq Y \\leq k+0.5)\\) on a normal dist., where \\(Y \\sim \\mathcal{N}(np, np(1-p))\\).</p> <p>Hence, \\(\\mathbb{P}(X \\leq k) = \\mathbb{P}(Y \\leq k + 0.5) = \\approx \\Phi(\\cfrac{k+0.5-np}{\\sqrt{np(1-p)}})\\)</p> <p>The value \\(0.5\\) is known as the continuity correction. </p> <p>Try act 3, 4 and 5 from W8C1</p>"},{"location":"maths/notes/#q-q-quantile-quantile-plot","title":"Q-Q (Quantile-Quantile) Plot","text":"<p>This plot is a graphical way to check which type of distribution some collected data best fits</p> <p>The \\(p\\)th quantile (aka percentile) of \\(X\\) is an \\(x\\)-value \\(Q_p\\) such that \\(\\mathbb{P}(X = Q_p) = F(Q_p) = p\\)</p> <p>If \\(p = 1/2\\) then \\(Q_p\\) is the median.</p> <p>If the CDF is a strictly increasing function (normal and exp), then \\(Q_p = F^{-1}(p)\\)</p> <p>If we plot the \\(p\\)th quantile of any normal distribution against the \\(p\\)th quantiles of the standard normal for various values of \\(p\\), then the plot forms a straight line. (A similar result is true for exponential distribution)</p> <p>In general, if the data comes from a random variable \\(X\\) then \\(x_i\\) should be close to the \\(\\cfrac{i}{n+1}\\)th quantile of \\(X\\)</p>"},{"location":"maths/notes/#to-construct-a-q-q-plot","title":"To construct a Q-Q plot","text":"<p>The above observation leads to the following procedure for constructing a Q-Q plot:</p> <ol> <li>Order the data values as \\(x_1 \\leq x_2 \\leq x_3 \\leq ... \\leq x_n\\).</li> <li>If you suspect that the data comes from a certain distribution, then construct a scatter plot of \\(x_i\\) against the \\(\\cfrac{i}{n+1}\\) th quantiles of such a distribution.</li> <li>Special case: if you suspect the data to be normal, then plot \\(x_i\\) against \\(\\Phi^{-1}(\\cfrac{i}{n+1})\\) this is known as a normal probability plot.</li> <li>If the scatter plot is close to a straight line, then the data could be modelled by said distribution</li> </ol>"},{"location":"maths/notes/#functions-of-random-variables","title":"Functions of Random Variables","text":"<p>if we have some \\(Y = g(X)\\) and the CDF/PDF of \\(X\\) is known, then we can find the \\(CDF/PDF\\) of \\(Y\\). \\(Y \\in range(g)\\)</p> <p>\\(F_y(y) = \\mathbb{P}(Y \\leq y)\\)</p> <p>\\(F_y(y) = \\mathbb{P}(g(X) \\leq y)\\)</p> <p>\\(F_y(y) = \\mathbb{P}(X \\leq g^{-1}(y))\\) (note that the inequality might change when solving for g^{-1}, square roots, or flips)</p> <p>\\(F_y(y) = F_x(g^{-1}(y))\\) here, \\(y \\in domain(g^{-1})\\)</p> <p>differentiating:</p> <p>\\(f_y(y) = f_x(g^{-1}(y))(g^{-1}(y))'\\)</p>"},{"location":"maths/notes/#discrete-joint-random-variables","title":"Discrete Joint Random Variables","text":""},{"location":"maths/notes/#joint-pmf","title":"Joint PMF","text":"<p>let \\(X\\) and \\(Y\\) be some discrete random variables. The joint pmf is defined as:</p> \\[ f(x, y) = \\mathbb{P}(X = x \\cap Y = y)\\] <p>\\(f(x, y)\\) must satisfy that \\(\\sum\\limits_{\\forall x}\\sum\\limits_{\\forall y} f(x, y) = 1\\)</p>"},{"location":"maths/notes/#marginal-pmf","title":"Marginal PMF","text":"<p>Marginal pmf of \\(X\\), denoted as \\(f_X\\) is defined as:</p> \\[ f_X(x) = \\mathbb{P}(X = x) = \\sum\\limits_{\\forall y} f(x, y) \\] <p>Similarly, marginal pmf of \\(Y\\), denoted as \\(f_Y\\) is defined as:</p> \\[ f_Y(y) = \\mathbb{P}(Y = y) = \\sum\\limits_{\\forall x} f(x, y) \\] <p>The marginal pmfs are the row/column sums of the joint pmf table, and since they're usually written in the margins of the joint pmf table, they're called marginal pmfs.</p> <p>can ask: \\(\\mathbb{P}(X + Y = n)\\)</p>"},{"location":"maths/notes/#independence-of-rv","title":"Independence of RV","text":"<p>Two random variables \\(X\\) and \\(Y\\) are independent</p> <p>iff \\(X \\in A\\) and \\(Y \\in B\\) are independent \\(\\forall A, B \\subseteq \\mathbb{R}\\)</p> <p>iff \\(\\mathbb{P}(X \\in A \\cap Y \\in B) = \\mathbb{P}(X \\in A)\\mathbb{P}(Y \\in B) \\forall A, B \\subseteq \\mathbb{R}\\)</p> <p>iff \\(f(x, y) = f_X(x) f_Y(y) \\forall x, y \\subseteq \\mathbb{R}\\)</p>"},{"location":"maths/notes/#expected-value-of-functions-over-joint-random-variables","title":"Expected Value of functions over Joint random variables","text":"\\[ \\mathbb{E}(g(X, Y)) = \\sum\\limits_{\\forall x} \\sum\\limits_{\\forall y} g(x, y) f(x, y) \\] <p>Theorem: </p> \\[ \\mathbb{E}(X + Y) = E(X) + E(Y) \\]"},{"location":"maths/notes/#continuous-joint-random-variables","title":"Continuous Joint Random Variables","text":""},{"location":"maths/notes/#joint-pdf","title":"Joint PDF","text":"\\[ \\mathbb{P}((X, Y) \\in C) = \\int\\int_{(x, y) \\in C} f(x, y)dx dy \\] <p>specifically, if the region is rectangular \\([a, b] \\times [c, d]\\) then</p> \\[ \\mathbb{P}((X, Y) \\in C) = \\int\\limits_c^d\\int\\limits_a^b f(x, y)dx dy \\] \\[ \\int\\limits_{-\\infty}^{\\infty}\\int\\limits_{-\\infty}^{\\infty} f(x, y)dx dy = 1\\] <p>Once again, \\(f(x, y)\\) is not a probability on its own. But for small \\(\\delta x\\) and \\(\\delta y\\), \\(f(x, y)\\delta x \\delta y = \\mathbb{P}(X \\in [x, x + \\delta x], Y \\in [y, y + \\delta y])\\)</p>"},{"location":"maths/notes/#marginal-pdf","title":"Marginal pdf","text":"\\[ \\mathbb{P}(X = x) = \\int\\limits_{-\\infty}^{\\infty} f(x, y) dy\\] \\[ \\mathbb{P}(Y = y) = \\int\\limits_{-\\infty}^{\\infty} f(x, y) dx\\]"},{"location":"maths/notes/#expected-value","title":"Expected Value","text":"\\[ \\mathbb{E}(g(X, Y)) = \\int\\limits_{-\\infty}^{\\infty}\\int\\limits_{-\\infty}^{\\infty} g(x, y) f(x, y)dx dy \\]"},{"location":"maths/notes/#independence-of-continuous-rv","title":"Independence of Continuous RV","text":"<p>exactly the same as discrete</p> <p>iff \\(\\mathbb{P}(X \\in A \\cap Y \\in B) = \\mathbb{P}(X \\in A)\\mathbb{P}(Y \\in B) \\forall A, B \\subseteq \\mathbb{R}\\)</p> <p>iff \\(f(x, y) = f_X(x) f_Y(y) \\forall x, y \\subseteq \\mathbb{R}\\)</p> <p>the two conditions are equivalent</p>"},{"location":"maths/notes/#joint-cdf","title":"Joint CDF","text":"<p>\\(F(x, y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\)</p> <p>\\(\\lim\\limits_{y \\to \\infty} F(x, y) = F_X(x)\\)</p> <p>\\(\\lim\\limits_{x \\to \\infty} F(x, y) = F_Y(y)\\)</p> <p>\\(\\mathbb{P}(X &gt; x, Y &gt; y) = 1 - F_X(x) - F_Y(y) + F(x, y)\\)</p>"},{"location":"maths/notes/#sum-of-independent-rvs","title":"Sum of Independent RVs","text":"<p>If \\(X \\sim binomial(n, p)\\) and \\(Y \\sim binomial(m, p)\\) then \\(X + Y \\sim binomial(n + m, p)\\). This is intuitive: \\(n\\) trials followed by \\(m\\) trials is equivalent to \\(m + n\\) trials.</p> <p>If \\(X \\sim poisson(\\lambda)\\) and \\(Y \\sim poisson(\\mu)\\) then \\(X + Y \\sim poisson(\\lambda + \\mu)\\). This is intuitive as well, \\(X\\) occurs \\(\\lambda\\) times on avg, \\(Y\\) occurs \\(\\mu\\) times on avg, This means that \\(X + Y\\) will occur \\(\\lambda + \\mu\\) times on average.</p>"},{"location":"maths/notes/#expectation_1","title":"Expectation","text":"<p>\\(\\mathbb{E}(X+Y) = \\mathbb{E}(X) + \\mathbb{E}(Y)\\)</p> <p>\\(\\mathbb{E}(aX+bY+c) = a\\mathbb{E}(X) + b\\mathbb{E}(Y) + c\\)</p>"},{"location":"maths/notes/#variance_1","title":"Variance","text":"<p>\\(Var(X+Y) = \\mathbb{E}((X + Y)^2) - \\mathbb{E}((X + Y))^2\\)</p> <p>\\(Var(X+Y) = \\mathbb{E}(X^2) + \\mathbb{E}(Y^2) + 2\\mathbb{E}(XY) - \\mathbb{E}(X)^2 - \\mathbb{E}(Y)^2 - 2\\mathbb{E}(X)\\mathbb{E}(Y)\\)</p> <p>\\(Var(X+Y) = \\mathbb{E}(X^2) - \\mathbb{E}(X)^2 + \\mathbb{E}(Y^2) - \\mathbb{E}(Y)^2 + 2(\\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y))\\)</p> <p>\\(Cov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\) which is $ = 0$ when X and Y are independent</p> <p>\\(Var(X+Y) = Var(X) + Var(Y) + 2Cov(X, Y)\\)</p> <p>\\(Var(X+Y) = Var(X) + Var(Y)\\)</p> <p>\\(Var(aX+bY+c) = a^2Var(X) + b^2Var(Y) + 2abCov(X, Y)\\)</p>"},{"location":"maths/notes/#covariance-of-independent-variables","title":"Covariance of Independent Variables","text":"\\[ \\mathbb{E}(XY) = \\int\\limits_{-\\infty}^{\\infty} \\int\\limits_{-\\infty}^{\\infty} xy f(x, y) dx dy \\] \\[ \\mathbb{E}(XY) = \\int\\limits_{-\\infty}^{\\infty} \\int\\limits_{-\\infty}^{\\infty} xy f_X(x) f_Y(y) dx dy \\] \\[ \\mathbb{E}(XY) = \\int\\limits_{-\\infty}^{\\infty} x f_X(x)dx \\int\\limits_{-\\infty}^{\\infty} y f_Y(y) dy \\] \\[ \\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y) \\] <p>If \\(X \\sim uniform(0, 1)\\) and \\(Y \\sim uniform(0, 1)\\) are independent RV, we can find \\(\\mathbb{P}(X + Y \\leq t) = \\int\\int_{x+y \\leq t} f(x, y) dx dy\\) and then differentiate to find the pdf</p> <p>We thus find that:</p> \\[  \\mathbb{P}(X + Y \\leq t) =      \\begin{cases}         \\cfrac{t^2}{2}  &amp; 0 &lt; t &lt; 1 \\\\         1 - \\cfrac{(2- t)^2}{2} &amp; 1 \\leq t \\leq 2 \\\\         0 &amp; otherwise     \\end{cases} \\] <p>and on differentiating:</p> \\[  \\mathbb{P}(X + Y = t) =      \\begin{cases}         t &amp; 0 &lt; t &lt; 1 \\\\         2-t &amp; 1 \\leq t \\leq 2 \\\\         0 &amp; otherwise     \\end{cases} \\] <p>If \\(X \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2)\\) and \\(Y \\sim \\mathcal{N}(\\mu_2, \\sigma_2^2)\\) are independent normal RV. \\(X + Y \\sim \\mathcal{N}(\\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2)\\)</p>"},{"location":"maths/notes/#independent-and-identitcally-distributed-rv","title":"Independent and Identitcally Distributed RV","text":"<p>A collection of RV is said to be IID if they are all independent and have the same distribution</p> \\[ \\bar{X}_n = \\cfrac{1}{n}\\sum\\limits_{i = 1}^{n} X_i \\] <p>\\(\\bar{X}_n\\) itself is an RV</p> <p>if Each individual dist has \\(\\mu\\) and \\(\\sigma^2\\) then \\(\\bar{X}_n\\) has \\(\\mu\\) and \\(\\cfrac{\\sigma^2}{n}\\)</p>"},{"location":"maths/notes/#law-of-large-numbers","title":"Law of large numbers","text":"<p>for any \\(\\epsilon &gt; 0\\)</p> \\[ \\lim_{n \\to \\infty} \\mathbb{P}(|\\bar{X}_n - \\mu| &lt; \\epsilon) = 1 \\] <p>LLN shows that the emperical frequency of any repeatable event converges to its theoretical Probability. To see this, let A be the event of interest, and \\(p = \\mathbb{P}(A)\\). \\(X_i = 1\\) if A occurs on the \\(i\\)th (independent) trial, and \\(0\\) otherwise. Then \\(\\bar{X}_n\\) is the empirical frequency of A, and by the LLN, it converges to \\(\\mu = \\mathbb{E}(X_i) = p\\).</p> <p>Likewise, the LLN shows that histograms constructed from data approximate the true pdf or pmf of the underlying RV. To see this, consider a bin in a histogram given by the interval \\([a, b)\\). \\(Y_i = 1\\) if the \\(i\\)th data point \\(X_i\\) falls into the bin, and \\(0\\) otherwise. Then \\(\\bar{Y}_n\\) is the proportion of data points in that bin, and it converges to \\(\\mu = \\mathbb{E}(Y_i) = \\mathbb{P}(a \\leq X_i &lt; b)\\)</p>"},{"location":"maths/notes/#central-limit-theorem-clt","title":"Central Limit Theorem (CLT)","text":"<p>If we have \\(n\\) IID RV with \\(\\mu\\) and \\(\\sigma^2 &lt; \\infty\\), Then for any \\(x \\in \\mathbb{R}\\)</p> \\[ \\lim_{n \\to \\infty} \\mathbb{P} (\\cfrac{{\\bar{X}_n - \\mu}}{\\sigma/\\sqrt{n}} \\leq x) = \\Phi(x) \\] \\[ \\cfrac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}} \\approx \\mathcal{N}(0, 1) = Z\\] \\[ \\bar{X}_n \\approx \\mathcal{N}(\\mu, \\sigma^2/n) \\] \\[ \\sum\\limits_{i=1}^{n} X_i \\approx \\mathcal{N}(n\\mu, n\\sigma^2) \\] <p>The limiting behaviour of this sum depends solely on the mean and variance of the dist. and not on their type</p> <p>Typically, \\(n \\geq 30\\) (if pdf or pmf symmetric/skewed \\(n\\) may be smaller/larger)</p>"},{"location":"maths/notes/#point-estimators","title":"Point Estimators","text":"<p>Parameters such as \\(\\mu\\) or \\(\\sigma^2\\) of the distribution are often unknown in practise. Given a dataset, \\(x_1\\), \\(x_2\\), ... \\(x_i\\) we would like to estimate them. If some unknown parameter \\(\\theta\\) is estimated using computations on the dataset, it is known as a point estimator and denoted as \\(\\hat{\\theta}\\)</p> <p>for the true mean \\(\\mu\\), we use \\(\\hat{\\mu} = \\bar{x}\\)</p> <p>for the true variance \\(\\sigma^2\\) we use \\(\\hat{\\sigma}^2 = S_x^2\\)</p>"},{"location":"maths/notes/#confidence-intervals","title":"Confidence Intervals","text":"<p>A point estimator is unlikely to give a value that actually agrees with the true parameter</p> <p>It would be more useful to give a range of possible values for the value being estimated. This would allow us to make statements like \"most of the time, \\(\\mu\\) lies in some interval A\"</p> <p>A confidence interval is an interval \\(A\\) for the estimate of a parameter \\(\\theta\\) such that</p> \\[\\mathbb{P}(\\theta \\in A) = 1-\\alpha\\]"},{"location":"maths/notes/#two-sided-cis","title":"Two sided CIs","text":"<p>if \\(A = [L, U]\\)</p> \\[\\mathbb{P}(L \\leq \\theta \\leq U) = 1-\\alpha\\] <p>Here, \\(\\alpha \\in (0, 1)\\) and \\(L, U\\) are computed from a sample</p> <p>\\([L, U]\\) is called a \\(100(1-\\alpha)\\%\\) (two sided) confidence interval for \\(\\theta\\)</p> <p>\\((1-\\alpha)\\) is called the confidence level. Using \\(\\alpha = 0.05\\) is very common, resulting in a \\(95\\%\\) confidence level</p> <p>Consider that a random sample \\(x_1\\), \\(x_2\\), ... \\(x_n\\) is drawn from a distribution \\(X\\) with \\(\\mu\\) and \\(\\sigma^2\\). Suppose that \\(n\\) is large and \\(\\mu\\) is unknown but \\(\\sigma^2\\) is known.</p> <p>We can then construct a \\(95\\%\\) confidence interval for \\(\\mu\\) by noting that \\(\\cfrac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}}\\) is approximately standard normal by the central limit theorem. Hence,</p> <p>\\(\\mathbb{P}(-1.96 \\leq \\cfrac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}} \\leq 1.96) = 0.95\\)</p> <p>\\(\\mathbb{P}(-1.96 \\cfrac{\\sigma}{\\sqrt{n}} \\leq \\bar{X}_n - \\mu \\leq 1.96 \\cfrac{\\sigma}{\\sqrt{n}}) = 0.95\\)</p> <p>\\(\\mathbb{P}(1.96 \\cfrac{\\sigma}{\\sqrt{n}} + \\bar{X}_n \\geq \\mu \\geq - 1.96 \\cfrac{\\sigma}{\\sqrt{n}} + \\bar{X}_n) = 0.95\\)</p> <p>Generally, let \\(z_{\\alpha/2} = \\Phi^{-1}(1-\\cfrac{\\alpha}{2})\\)</p> <p>Then we have that \\(100(1-\\alpha)\\%\\) two-sided confidence interval for \\(\\mu\\) is given by</p> \\[ \\left[ \\bar{x} - z_{\\alpha/2} \\cfrac{\\sigma}{\\sqrt{n}}, \\bar{x} + z_{\\alpha/2} \\cfrac{\\sigma}{\\sqrt{n}} \\right] \\] <p>If the distribution is known to be normal, then we don't need \\(n\\) to be very large, it works for any \\(n \\in \\mathbb{N}\\)</p> <p>Once a confidence interval has been calculated, the true mean \\(\\mu\\) either lies inside it, or it does not. So, technically speaking, it is incorrect to say that \u00b5 lies inside the \\(95\\%\\) CI with probability = \\(95\\%\\).</p> <p>A better interpretation for the \\(95\\%\\) CI is: if we repeatedly draw samples of size \\(n\\) from the same distribution, and calculate the CI using the same method each time, then the proportion of CI\u2019s that contains \\(\\mu\\) will approach \\(95\\%\\)</p>"},{"location":"maths/notes/#one-sided-ci","title":"One sided CI","text":"<p>Lower \\(100(1-\\alpha)\\%\\) confidence interval: \\(\\left[ \\bar{x} - z_{\\alpha} \\cfrac{\\sigma}{\\sqrt{n}}, \\infty \\right)\\)</p> <p>Upper \\(100(1-\\alpha)\\%\\) confidence interval: \\(\\left( -\\infty, \\bar{x} + z_{\\alpha} \\cfrac{\\sigma}{\\sqrt{n}} \\right]\\)</p>"},{"location":"maths/notes/#unknown-variance","title":"Unknown Variance","text":"<p>In most applications, \\(\\sigma^2\\) is also unknown, and is estimated using \\(S_x^2\\). In general there is no limit theorem for \\(cfrac{\\bar{X}_n - \\mu}{S/\\sqrt{n}}\\)</p> <p>In the special case where \\(X_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) for all \\(1 \\leq i \\leq n\\) the distribution of \\(cfrac{\\bar{X}_n - \\mu}{S/\\sqrt{n}}\\) can be found using the Student's \\(t\\)-distribution with \\(n-1\\) degrees of freedom</p> <p>When \\(\\sigma^2\\) is unknown but \\(X_i\\) are IID normal RVs, the \\(100(1-\\alpha)\\%\\) two sided CI is given by</p> \\[ \\left[ \\bar{x} - t_{n-1, \\alpha/2} \\cfrac{\\sigma}{\\sqrt{n}}, \\bar{x} + t_{n-1, \\alpha/2} \\cfrac{\\sigma}{\\sqrt{n}} \\right] \\] <p>\\(t_{n-1, \\alpha/2}\\) comes from the inverse CDF of a \\(t\\)-distribution. Its values are also tabulated like \\(\\Phi\\). <code>T.INV(1-\\alpha/2, n-1)</code> may be used in Excel</p> <p>The one sided CIs are given by:</p> <p>Lower \\(100(1-\\alpha)\\%\\) confidence interval: \\(\\left[ \\bar{x} - t_{n-1, \\alpha/2} \\cfrac{\\sigma}{\\sqrt{n}}, \\infty \\right)\\)</p> <p>Upper \\(100(1-\\alpha)\\%\\) confidence interval: \\(\\left( -\\infty, \\bar{x} + t_{n-1, \\alpha/2} \\cfrac{\\sigma}{\\sqrt{n}} \\right]\\)</p>"},{"location":"maths/notes/#t-distributions","title":"\\(t\\)-distributions","text":"<p>\\(t\\)-distribution is a family of continuous distributions that depend on \\(n\\). It converges to the standard normal as \\(n \\to \\infty\\)</p> <p>Each \\(t\\)-distribution is a symmetric bell shaped curve symmetric around \\(0\\), but has heavier tails than the SND. Using it thus gives wider CIs (in)</p>"},{"location":"maths/notes/#hypothesis-testing","title":"Hypothesis Testing","text":"<p>To answer questions such as: is A better than B?</p> <p>In hypothesis testing, we try to infer some information about the population from a sample; more specifically, we attempt to answer this: given a sample, does it provide statistically significant evidence to prove beyond reasonable doubt a hypothesis about the population?</p> <p>To do so, we use data to test the validity of a claim about the population, against a counter claim. We set up the two competing claims as follows:</p> <p>The null hypothesis, \\(H_0\\). Usually, \\(H_0\\) is the claim of no difference or no effect; the status quo / conservative stance.</p> <p>The alternative hypothesis, \\(H_1\\), which is the logical negation of \\(H_0\\). Usually, \\(H_1\\) is the claim that there is a difference or effect; a change from a well-accepted current practice.</p>"},{"location":"maths/notes/#computing-intervals","title":"Computing Intervals","text":"<p>A random IID sample of \\(n\\) values \\(X_i\\) drawn from a distribution with unknown \\(\\mu\\) but known \\(\\sigma^2\\). If \\(n\\) is sufficiently large, we can use CLT to test \\(H_0 : \\mu = \\mu_0\\) vs \\(H_1 : \\mu \\neq \\mu_0\\)</p> <p>Assuming that \\(H_0\\) is true, we have that \\(\\cfrac{\\bar{X}_n - \\mu_0}{\\sigma / \\sqrt{n}} \\sim \\mathcal{N}(0, 1)\\). Thus:</p> \\[ \\mathbb{P}(-z_{\\alpha/2} \\leq \\cfrac{\\bar{X}_n - \\mu_0}{\\sigma / \\sqrt{n}} \\leq z_{\\alpha/2}) = 1 - \\alpha \\] <p>Hence, we \\(\\color{red}\\text{reject H0 in favour of H1}\\) iff \\(\\bar{x}\\) lies outside the above interval for a given \\(\\alpha\\) (probability of type I error, aka significance level, usually small, ~ \\(0.1\\), \\(0.05\\), \\(0.01\\))</p> <ol> <li> <p>\\(H_1 : \\mu &gt; \\mu_0\\): we \\(\\color{red}\\text{reject H0 in favour of H1}\\) iff \\(\\bar{x}\\) lies outside the upper bound one sided interval</p> </li> <li> <p>\\(H_1 : \\mu &lt; \\mu_0\\): we \\(\\color{red}\\text{reject H0 in favour of H1}\\) iff \\(\\bar{x}\\) lies outside the lower bound one sided interval</p> </li> </ol>"},{"location":"maths/notes/#p-value","title":"p-value","text":"<p>Another approach to hypothesis testing: assuming \\(H_0\\) is true, whats the probability of observing an outcome at least as extreme as the one observed? If this probability is less than \\(\\alpha\\) (the significance level) we reject \\(H_0\\). This probability is thus known as the p-value</p> <p>It is the smallest value of \\(\\alpha\\) for which \\(H_0\\) can be rejected.</p> <p>Note: Definition of at least as extreme depends on context! It could be deviation on either side of the mean, it depends on the question and its context!</p> <p>Note that this is actually equivalent to the first method, because the p-value is less than \\(\\alpha\\) iff the \\(\\bar{x}\\) lies outside of our computed CI for that \\(\\alpha\\) .</p>"},{"location":"maths/notes/#power","title":"Power","text":"<p>The probability of correctly rejecting \\(H_0 : \\mu = \\mu_0\\) in favour of \\(H_1 : \\mu = \\mu_1 &gt; \\mu_0\\) is known as the power of the test. This probability is dependent on the true mean \\(\\mu_1\\) of the distribution. Basically, its the probability that our observed sample mean is higher than \\(\\mu_0 + z_{\\alpha} \\cfrac{\\sigma}{\\sqrt{n}}\\), because that is when we reject the null hypothesis.</p> <p>Thus:</p> \\[ 1-\\beta = \\mathbb{P}(\\bar{X}_n &gt; \\mu_0 + z_{\\alpha} \\cfrac{\\sigma}{\\sqrt{n}}) \\] \\[ 1-\\beta = \\mathbb{P}(Z &gt; \\cfrac{\\mu_0 - \\mu_1}{\\cfrac{\\sigma}{\\sqrt{n}}} + z_{\\alpha}) \\] \\[ \\text{power} = 1-\\beta = \\mathbb{P}(Z &lt; \\cfrac{\\mu_1 - \\mu_0}{\\cfrac{\\sigma}{\\sqrt{n}}} - z_{\\alpha}) \\] \\[ \\beta = 1 - \\mathbb{P}(Z &lt; \\cfrac{\\mu_1 - \\mu_0}{\\cfrac{\\sigma}{\\sqrt{n}}} - z_{\\alpha}) \\] <p>\\(\\beta\\) is the probability of committing a type II error. (failing to reject \\(H_0\\) when it is false)</p>"},{"location":"maths/notes/#residuals","title":"Residuals","text":"<p>If we have some data \\((x_i, y_i)\\) and we draw the regression line for it using the equation \\(\\hat{y} = \\beta_0+ + \\beta_1x\\) then for each \\(y_i\\), we have a residual defined as \\(e_i = y_i - \\hat{y}_i\\)</p> <p>If the data is actually linear in reality, then the residual values are IID normal random variables (assuming that the errors are measurement errors)</p> <p>Hence, an \\((x_i, e_i)\\) plot (known as a residual plot) should hold the following properties:</p> <ol> <li>It should be randomly distributed</li> <li>The vertical spread of residuals (standard deviation of the \\(\\epsilon_i\\)) should remain constant</li> <li>The Q-Q plot of the residuals can be used to test for normality as well.</li> </ol> <p>If the residual plot is a parabola, the regression may need an \\(x^2\\) term</p> <p>The variance of the residuals can be estimated by the mean squared error:</p> <p>\\(s^2 = \\cfrac{1}{n-2} \\sum\\limits^n_{i=1}e_i^2\\)</p> <p>generally, any \\(e_i &gt; 2s\\) implies outlier </p>"},{"location":"maths/notes/#distribution-of-beta_1","title":"Distribution of \\(\\beta_1\\)","text":"<p>\\(\\hat{\\beta}_1 \\sim \\mathcal{N}(\\beta_1, \\cfrac{\\sigma^2}{(n-1) s_x^2})\\) (w13c1 for proof)</p> <p>plug this into the confidence interval formula for an SND \\(\\sim \\mathcal{N}(\\mu, \\sigma^2)\\) with \\(n\\) observations</p> \\[ \\mathbb{P}(-z_{\\alpha/2} \\leq \\cfrac{\\hat{\\beta}_1 - \\beta_1}{\\sigma/(s_x\\sqrt{n-1})} \\leq z_{\\alpha/2}) = 1 - \\alpha \\] <p>since \\(\\sigma^2\\) is unknown in practise, it is replaced with \\(s^2\\) (MSE) and then the t-distribution is utilised to find the CI.</p>"},{"location":"maths/notes/#hypothesis-testing_1","title":"Hypothesis Testing","text":"<p>if we have \\(H_0 : \\beta_1 = b_1\\) vs \\(H_1 : \\beta_1 \\neq b_1\\)</p> <p>We can reject \\(H_0\\) in favour of \\(H_1\\) at significance level \\(\\alpha\\) if \\(b_1\\) lies outside the CI constructed using the given \\(\\alpha\\)</p>"},{"location":"maths/notes/#maximum-likelyhood-estimation","title":"Maximum likelyhood estimation","text":"<p>We can use the sample mean and sample variance to approximate the mean and variance of a dist.</p> <p>In general, a distribution may contain parameters that are different from its mean and var. To find/estimate such parameters, the goal is to pick such a value for them that maximises the probability of seeing the given data.</p> <p>For instance, if we know that a biased coin has some probability \\(p\\) to give \\(T\\), and we observe \\(T T T H T\\), then intuitively the value of \\(p\\) that maximises this outcome is \\(p = 4/5\\). This can be shown by maximising \\(\\mathbb{P} = p^4 (1-p)\\)</p> <p>In general, if we have a pdf with a parameter: \\(f(x | t)\\) and \\(n\\) IID observations \\(x_i\\), then we can write the probability of obserivng the outcome as:</p> \\[ L(t) = \\prod\\limits_{i = 1}^{n} f(x | t)\\] <p>This function is known as the likelyhood function (probability) of observing the given outcome. Now we can maximise this to find the parameter \\(t\\).</p>"},{"location":"maths/to_know/","title":"Important Information","text":""},{"location":"phy/deadlines/","title":"Important Deadlines","text":"<p>Pset 2 - 18<sup>th</sup> Oct</p>"},{"location":"phy/notes/","title":"Notes","text":""},{"location":"phy/notes/#definitions","title":"Definitions:","text":"<p>System: a region w en/matter separated from the surr. by arbitrarily imposed wall of boundary Boundary: an arbitrary closed surface through which en/mass enter/leave the sys Surrounding: anything that interacts w the sys</p> <p>props: things that describe the sys. temp, pressure, vol, etc.</p> <p>Closed sys: no transfer of en across the boundary Open sys: transfer of en across the boundary</p> <p>Heat: En transfer due to temp diff only. higher -&gt; lower</p>"},{"location":"phy/notes/#first-law-of-td-conservation-of-energy","title":"First law of TD: Conservation of Energy","text":"<p>Energy can be transformed from 1 form to another, but can neither be created nor destroyed</p> <p>Energy: state function</p> <p>\\(\\Delta E_{sys} = (\\sum E_{sys,2} - \\sum E_{sys,1})\\)</p> <p>This holds for first der. wrt time.</p> <p>\\(\\dot{E}_{sys} = \\Delta \\dot{Q} + \\Delta \\dot{W} + \\Delta \\dot{E}_{flow}\\)</p> <p>Energy can be transfered in the form of heat (flow of heat), in the form of work done (power) and in the form of mass (energy \\(\\dot{E_{flow}}\\) )</p> <p>for a closed sys, \\(\\dot{E}_{sys} = \\dot{U}_{sys} = \\Delta \\dot{Q} + \\Delta \\dot{W}\\)</p>"},{"location":"phy/notes/#heat-transfer","title":"Heat Transfer","text":"<p>Bodies do not contain heat, its only id-ed as it passes across the sys bounds</p>"},{"location":"phy/notes/#modes-of-heat-transfer","title":"Modes of Heat Transfer","text":""},{"location":"phy/notes/#conduction","title":"Conduction","text":"<p>By intermol. interactions</p> <p>Fourier's Law: \\(\\dot{Q} =  -\\kappa A \\frac{dT}{dx}\\)</p> <p>\\(\\kappa\\) - therm conduct.</p>"},{"location":"phy/notes/#convection","title":"Convection","text":"<p>By diffusion n bulk movement of fluid. Occurs b/n surfaces</p> <p>Newton's Law of cooling: \\(\\dot{Q} = h A (T_h - T_c)\\)</p> <p>h - heat transfer coeff.</p> <ol> <li>Forced: due to pump/fan/external cause. ex: fan over PCB</li> <li>Free: Naturally due to buoyncy effects and differences in density. ex: air in contact w hot things</li> </ol>"},{"location":"phy/notes/#radiation","title":"Radiation","text":"<p>By EM rad. No medium req. Dominant method of heat transfer for temp &gt; 400\u00b0C</p> <p>Stefan-Boltzman Law: \\(\\dot{Q} = \\epsilon \\sigma A (T_h^4 - T_c^4)\\)</p> <p>\\(\\epsilon\\) - emissivity \\((0 &lt; \\epsilon &lt; 1)\\)</p> <p>\\(\\sigma\\) - Stefan-Boltzman Const \\((5.67 \\times 10^{-8})\\)</p>"},{"location":"phy/notes/#steady-and-transient-state","title":"Steady and Transient state","text":"<p>Steady state: in = out. \\(\\dot{Q}_{conv} = \\dot{Q}_{cond} = \\dot{Q}_{rad}\\)</p>"},{"location":"phy/notes/#work","title":"Work","text":"<p>Work is power out/in</p>"},{"location":"phy/notes/#electrical-analog-for-conduction-and-convection","title":"Electrical Analog for Conduction and Convection","text":"<p>\\(\\dot{Q}_{cond} =  -\\kappa A \\frac{dT}{dx} = \\cfrac{T_2-T_1}{\\cfrac{L}{\\kappa A}} = \\cfrac{\\Delta T}{R_{cond}}\\)</p> <p>\\(\\dot{Q}_{conv} = h A (T_h - T_c) = \\cfrac{T_2-T_1}{\\cfrac{1}{h A}} = \\cfrac{\\Delta T}{R_{conv}}\\)</p> <p>Thus,</p> <p>\\(R_{cond} = \\cfrac{L}{\\kappa A}\\)</p> <p>\\(R_{conv} = \\cfrac{1}{h A}\\)</p> <p>Here, \\(T\\) is analogous to \\(V\\) and \\(Q\\) is analogous to \\(I\\). A similar analysis can be done to compare series and parallel heat flow!</p>"},{"location":"phy/notes/#conservation-of-mass-energy","title":"Conservation of Mass &amp; Energy","text":"<p>Definition of boundaries are important for system. Include them in your answers</p>"},{"location":"phy/notes/#conservation-of-mass","title":"Conservation of Mass","text":"<p>Mass can neither be created nor destroyed</p>"},{"location":"phy/notes/#mass-flow-rate","title":"Mass flow rate","text":"<p>Control Volume</p> <p>\\(\\cfrac{dm_{cv}}{dt} = \\cfrac{dm_{sys}}{dt} = in - out\\)</p> <p>This change is 0 in <code>Steady State</code></p>"},{"location":"phy/notes/#conservation-of-energy","title":"Conservation of Energy","text":"<p>Energy can neither be created nor destroyed but it can be transformed from one form to another</p>"},{"location":"phy/notes/#flow-work","title":"Flow Work","text":"<p>\\(\\dot{W}_i = P_i \\dot{m}_i v_i\\) - in</p> <p>\\(\\dot{W}_e = P_e \\dot{m}_e v_e\\) - out (effluent?)</p> <p>P - Pressure, m - mass flow rate, v = 1/density (specific volume, volume of 1 kg of mat)</p> <p>\\(u_{internal} = PE + KE\\) ,</p> <p>\\(h = u_{internal} + Pv\\)</p> <p>\\(\\dot{E}_{flow, in} - \\dot{E}_{flow, out} = \\dot{m}_{in} h_{in} + \\dot{m}_{in} g z_{in} + \\frac{1}{2}\\dot{m}_{in} v^2_{in} - (\\dot{m}_{out} h_{out} + \\dot{m}_{out} g z_{out} + \\frac{1}{2}\\dot{m}_{out} v^2_{out})\\)</p>"},{"location":"phy/notes/#entropy","title":"Entropy","text":"<p>\\(\\Delta S = \\cfrac{\\delta Q}{T}\\)</p> <p>\\(\\cfrac{dS_{sys}}{dt} = \\sum\\cfrac{\\dot{Q}_{in, j}}{T_j} - \\sum\\cfrac{\\dot{Q}_{out, j}}{T_j} + \\sum \\dot{m}_i s_i - \\sum \\dot{m}_e s_e + \\dot{\\sigma}_{gen, cv}\\)</p> <p>s - specific entropy</p> <p>\\(\\dot{\\sigma}_{gen, cv} \\geq 0\\) Always</p> <p>When reading the entropy values from table, if the pressure is not 1 Bar, you need to correct for the term:</p> <p>\\(s_2 - s_1 = s^{\\circ}_2 - s^{\\circ}_1 - rln\\cfrac{P_2}{P_1}\\)</p> <p>r = gas constant, \\(\\cfrac{R}{M_w}\\)</p> <p>\\(R = 8.314 J/mol.K\\)</p>"},{"location":"phy/notes/#efficiency","title":"Efficiency","text":"<p>\\(\\eta = \\cfrac{W_{out}}{Q_h} = \\cfrac{Q_h - Q_c}{Q_h}\\)</p> <p>\\(\\eta_{carnot} = 1 - \\cfrac{T_C}{T_H}\\)</p> <p>\\(COP_{ref} = \\cfrac{Q_c}{W_{in}} = \\cfrac{Q_c}{Q_h - Q_c} = \\cfrac{T_c}{T_h - T_c}\\)</p> <p>\\(COP_{heat} = \\cfrac{Q_h}{W_{in}} = \\cfrac{Q_h}{Q_h - Q_c} = \\cfrac{T_h}{T_h - T_c}\\)</p>"},{"location":"phy/notes/#exergy","title":"Exergy","text":"<p>A sys delivers the max possible work if it goes through a rev. process from initial to final (dead) state.</p> <p>Dead State =&gt; in thermodynamic equilibrium with its surroundings. Repr by subscript 0</p> <p>Exergy is defined as the maximum possible work which represents useful work potential of the system at a specific state</p>"},{"location":"phy/notes/#irreversibility-and-reversible-work","title":"Irreversibility and Reversible work","text":"<p>\\(I = W_{rev, out} - W_{out}\\)</p> <p>\\(I = W_{in} - W_{rev, in}\\)</p> <p>Irrevrsibility is equivalent to exergy destroyed as it is viewed as wasted work potential or lost opportunity to do work</p> <p>Reversible work is the maximum amount of useful work that can be produced as a system undergoes a process between the specific initial and final states</p> <p>if \\(\\dot{\\sigma}_{gen} = 0\\) then all work is reversible</p> <p>\\(\\eta_{carnot} = \\eta_{rev} = \\cfrac{W_{rev,out}}{Q_h}\\)</p>"},{"location":"phy/notes/#exergy-for-fixed-mass-system","title":"Exergy for fixed mass system","text":"<p>\\(X = U-U_0 + P_0(V-V_0) - T_0(S-S_0) + \\cfrac{mv^2}{2} + mgz\\)</p> <p>specific exergy:</p> <p>\\(\\phi = u-u_0 + P_0(v-v_0) - T_0(s-s_0) + \\cfrac{v^2}{2} + gz\\)</p> <p>\\(X_2 - X_1 = U_2-U_1 + P_0(V_2-V_1) - T_0(S_2-S_1) + \\cfrac{m(v_2^2 - v_1^2)}{2} + mg(z_2-z_1)\\)</p>"},{"location":"phy/notes/#exergy-transfer-accompanying-work","title":"Exergy Transfer Accompanying Work","text":"<p>\\(X = W = nRT.ln(\\cfrac{V_2}{V_1})\\)</p>"},{"location":"phy/notes/#exergy-transfer-accompanying-heat","title":"Exergy Transfer Accompanying Heat","text":"<p>\\(X = \\dot{W} = \\eta_{carnot}\\dot{Q} = (1 - \\cfrac{T_0}{T})\\dot{Q}\\)</p> <p>\\(\\dot{X} = \\dot{X}_{in} - \\dot{X}_{out} - \\dot{X}_{destroyed}\\)</p> <p>\\(\\dot{X}_{in} = \\dot{X}_{heat, in} + \\dot{X}_{work, in}\\)</p> <p>\\(\\dot{X}_{out} = \\dot{X}_{heat, out} + \\dot{X}_{work, out}\\)</p> <p>\\(I = X_{destroyed} = W_{lost} = T_0 \\sigma_{gen}\\)</p>"},{"location":"phy/notes/#second-law-exergetic-efficiency","title":"Second Law (Exergetic Efficiency)","text":"<p>\\(\\epsilon = \\cfrac{\\eta}{\\eta_{rev}} = \\cfrac{COP}{COP_{rev}}\\)</p> <p>\\(\\epsilon = \\cfrac{W_{out}}{W_{rev, out}} = \\cfrac{W_{rev, in}}{W_{in}}\\)</p> <p>left one =&gt; power producing devices, right one =&gt; power consuming devices</p> <p>\\(\\epsilon = \\cfrac{\\text{exergy recovered}}{\\text{exergy supplied}} = 1 - \\cfrac{\\text{exergy destroyed}}{\\text{exergy supplied}}\\)</p> <p>\\(\\text{exergy recovered} = \\dot{m}_{in}{\\psi_{in}} - \\dot{m}_{out}{\\psi_{out}}\\)</p> <p>\\(\\text{exergy supplied} = \\dot{X}_{in}\\)</p>"},{"location":"phy/notes/#exergy-flow-in-an-open-sys","title":"Exergy Flow in an Open Sys.","text":"<p>Specific exergy:</p> <p>\\(\\psi = (u - u_0) + (Pv - P_0 v_0) - T_0(s - s_0) + \\cfrac{v^2}{2} + gz\\)</p> <p>\\(h = u + Pv\\)</p> <p>\\(\\psi = (h - h_0) - T_0(s - s_0) + \\cfrac{v^2}{2} + gz\\)</p> <p>\\(\\cfrac{dX_{sys}}{dt} = \\dot{X}_{heat, in} - \\dot{X}_{heat, out} + \\dot{X}_{work, in} - \\dot{X}_{work, out} + \\sum \\dot{m_{in}}\\psi_{in} - \\sum \\dot{m_{out}}\\psi_{out}\\)</p>"},{"location":"phy/notes/#batteries","title":"Batteries","text":""},{"location":"phy/notes/#important-battery-parameters-to-consider","title":"Important Battery Parameters to Consider","text":"<ol> <li>Cell Voltage \\(E^{\\circ}_{cell}\\)</li> <li>Energy Density/Specific Energy</li> <li>Capacity</li> </ol> <p>Not in focus</p> <ol> <li>Power Density/Specific Power</li> <li>Self\u2010discharge rate/charging cycles</li> <li>Charge\u2010Discharge rate life time</li> <li>Capital/Operating cost</li> </ol>"},{"location":"phy/notes/#specific-energy","title":"Specific Energy","text":"<p>Energy stored per unit mass of battery (specific energy)</p> <p>\\(e = \\cfrac{V.n.q}{m}\\)</p> <p>Energy stored per unit volume of battery (energy density)</p> <p>\\(e = \\cfrac{V.n.q}{v}\\)</p> <p>\\(V\\) - Voltage, \\(n\\) - num of electrons, \\(q\\) - charge on one electron, \\(m\\) - mass of active materials, \\(v\\) - volume of active materials</p>"},{"location":"phy/notes/#current","title":"Current","text":"<p>C-rate - The rate of time in which it takes to charge or discharge This is the value of current in amperes that is numerically equal to the batter's capacity in Ampere hours</p>"},{"location":"phy/notes/#voltage","title":"Voltage","text":"<p>emf is different for different currents drawn. Higher current =&gt; lesser voltage. This is because more active mass is used =&gt; the potential difference between the cathode and anode is reduced fast</p> <p>\\(E_{cell} = E^{\\circ}_{cell} - \\cfrac{RT}{nF}ln(Q)\\)</p> <p>Q - Reaction Quotient</p> <p>\\(F = N_a \\times e = 96500 C\\)</p> <p>charge on one mole of electrons, Faraday's constant</p> <p>Nominal Voltage - (midpt voltage) Voltage when the battery is at \u00bd capacity</p>"},{"location":"phy/notes/#capacity","title":"Capacity","text":"<p>\\(\\text{Capacity} = \\text{Current} \\times \\text{Time}\\)</p> <p>Look at the discharge characterisitics from week 6 cohort 2</p>"},{"location":"phy/notes/#self-discharge-rate","title":"Self Discharge rate","text":"<p>Self\u2010discharge \u2010 loss of capacity through reactions during the battery storage and when battery is not connected to a load</p> <p>These reactions are mainly caused by thermodynamic instabilities between active masses and cell components, resulting in consumption of active masses</p> <p>Capacity decreases over time as a result of loss through self\u2010discharge</p> <p>Self\u2010discharge is usually reversible \u2010 battery is recharged the capacity is restored</p> <p>For lead\u2013acid batteries the product of discharge reaction is lead sulfate which may build and grow irreversibly if the recharge doesn\u2019t occur in a certain time \u2013 a battery if left for a long period of time without recharging, the available capacity will be reduced</p>"},{"location":"phy/notes/#applications-of-batteries","title":"Applications of Batteries","text":"<ol> <li>Electromotibility</li> <li>Standalone PV sys</li> <li>Mobile Application</li> <li>Backup/stationary batteries</li> </ol>"},{"location":"phy/notes/#different-types-of-pv-systems","title":"Different Types of PV Systems","text":"<p>Grid Tie - on roof Grid Tie - with backup batteries Off Grid - Standalone</p>"},{"location":"phy/notes/#different-components-in-a-standalone-pv-system","title":"Different Components in a Standalone PV System","text":"<ol> <li>Solar Panel - Source</li> <li>Energy Storage - Batteries</li> <li>Solar Charge Controller - Manages the charging of the battery and operation of the load. It ensures charging voltage and current are well controlled to protect the lifespan of the battery used.</li> <li>Load</li> </ol> <p>Steps to design a standalone system:</p> <ol> <li>Determine the load energy requirement</li> <li>Determin the Size of the battery</li> <li>Determin the Size of the PV sys</li> </ol>"},{"location":"phy/notes/#depth-of-discharge","title":"Depth of Discharge","text":"<p>\\(DOD = \\cfrac{\\text{capacity that is discharged from a fully charged battery}}{\\text{battery nominal capacity}}\\)</p>"},{"location":"phy/notes/#end-of-life","title":"End of Life","text":"<ol> <li>Batteries that have reached the end of their usefulness and/or lifespan and no longer operate at sufficient capacity</li> <li>Percent of capacity at EoL of battery is usually defined as 80% of original capacity</li> <li>It may be lower in other applications</li> </ol>"},{"location":"phy/notes/#days-of-autonomy","title":"Days of Autonomy","text":"<p>The number of days that the battery can supply the site\u2019s loads without any support from generation sources</p> <ol> <li>For a standalone PV system, it requires some battery reserve to ensure reliability of service and to provide time for intervention in the event of an unanticipated occurrence (e.g. poor weather or failure of a system component)</li> <li> <p>The number of days of autonomy is a system design requirement that takes the following into consideration:</p> <ol> <li>System application \u2013 critical load applications require more autonomy than non\u2010critical applications</li> <li>System availability \u2013 minimum percentage of the time that the PV system should be able to satisfy the system\u2019s specified design loads</li> <li>Solar irradiance variability \u2013 daily and seasonal variations in solar irradiance affect the required autonomy</li> <li>Predictability of load \u2013 load may not be predictable or the load may be adjusted such as when dropping nonessential loads</li> <li>Recharge capability \u2013 battery may not be fully recharged between discharges if the array is insufficiently sized or the recharge time is too short</li> <li>Accessibility of site \u2013 worse\u2010case time required to reach the site and to correct for any problem</li> </ol> </li> </ol>"},{"location":"phy/notes/#number-of-batteries","title":"Number of batteries","text":""},{"location":"phy/notes/#size-of-solar-panel","title":"Size of solar Panel","text":"<ol> <li>Using load requirement/avg daily irradiance for the area of the solar panel</li> <li>Simulation</li> </ol>"},{"location":"phy/notes/#materials-and-manufacturing-issues-of-li-ion-batteries","title":"Materials and manufacturing issues of Li-Ion batteries","text":"<ol> <li>Electron transport in solid</li> <li>Ionic diffusion in liquid and solid</li> <li>Structre/Volume change: strain</li> <li>Solid Electrolyte Interphase</li> <li>Saftey Control</li> </ol>"},{"location":"phy/notes/#irradianceintensity-wm2","title":"Irradiance/Intensity (\\(W/m^2\\))","text":"<p>\\(I = \\cfrac{\\partial P}{\\partial A}\\)</p> <p>\\(1 kW/m^2 = 1 \\; Sun\\) is the standard \\(I_{rad}\\) used to test solar cells.</p>"},{"location":"phy/notes/#spectral-irradiance-wm2nm","title":"Spectral Irradiance (\\(W/m^2.nm\\))","text":"<p>\\(S(\\lambda) = \\cfrac{\\partial I}{\\partial \\lambda} = \\cfrac{\\partial^2 P}{\\partial \\lambda \\partial A}\\)</p> <p>\\(I_{rad} = \\int\\limits_{\\lambda_1}^{\\lambda_2} S(\\lambda) d\\lambda\\)</p>"},{"location":"phy/notes/#formation-of-electron-hole-pairs","title":"Formation of Electron Hole Pairs","text":"<p>Typical Energy band diagrams</p> <ol> <li>Metals: Half filled conduction band (no band gap/overlapping conduction and valence band) (\\(Au\\), \\(Cu\\), \\(Al\\), \\(Ag\\))</li> <li>Semi Conductors: bad gap \\(&lt; 5 \\; eV\\) (\\(Si\\), \\(Ge\\), \\(GaAs\\), \\(BiTe\\), \\(ZnSe\\))</li> <li>Insulators: bad gap \\(&gt; 5 \\; eV\\) (\\(SiO_2\\))</li> </ol> <p>Generation: A photon with energy \\(E = hf &gt; E_{bg}\\) can knock off electrons from the valence band and excite them up to the conduction band. An electron hole pair is formed.</p> <p>Recombination: If not \"used\", the electron will fall back to the valance band, releasing energy in the form of light or heat</p> <p>Enter \\(n\\) and \\(p\\) type doping. When \\(n\\) and \\(p\\) doped sc are put next to each other, A region called the depletion region is created. It creates an \\(E\\) field that drives the flow of electrons and holes</p> <p>A PN junction diode allows the flow of current easily in one direction (Forward Bias) but resists the flow of current in the opposite direction (Reverse Bias)</p> <p>\\(I_D = I_o(e^{\\cfrac{eV}{k_B T}} - 1)\\)</p> <p>The diode current is opposite in direction to the photocurrent from a solar cell (\\(I_{sc}\\) (short circuit current))</p> <p>\\(I = I_o(e^{\\cfrac{eV}{k_B T}} - 1) - I_{sc}\\)</p> <p>\\(I_o\\): Reverse saturation current. Due to diffusive flow of minority electrons from the p side to the n side and the minority holes from the n to p side. Unaffected by rev bias but sensitive to temp changes</p> <p>When the solar panel is in operation, \\(I_{sc} &gt; I_o(e^{\\cfrac{eV}{k_B T}} - 1)\\) and the current is produced from the p terminal.</p> <p>The IV plot for a solar panel is usually flipped and the equation is as follows:</p> <p>\\(I_r = I_{sc} - I_o(e^{\\cfrac{eV}{k_B T}} - 1)\\)</p> <p>If the solar panel is not connected, \\(I_r = 0\\)</p> <p>\\(I_{sc} = I_o(e^{\\cfrac{eV}{k_B T}} - 1)\\)</p> <p>\\(V_{oc} = \\cfrac{K_B T}{e} ln\\left(\\cfrac{I_{sc}}{I_o} + 1\\right)\\)</p> <p>\\(I_o\\) is a function of \\(T\\) which grows much faster than the \\(T\\) in the numerator. \\(V_{oc}\\) decreases with increase in \\(T\\)</p> <p>The output power of a solar cell is \\(IV\\) determined experimentially by varying the resistive load.</p> <p>\\(P_{max} = I_{max} V_{max} = FF I_{sc} V{oc}\\)</p> <p>\\(FF = \\cfrac{P_{max}}{I_{sc} V_{oc}}\\)</p> <p>\\(FF\\) - Fill Factor</p> <p>\\(\\eta = \\cfrac{P_{out}}{P_{in}} = FF \\cfrac{I_{sc} V_{oc}}{P_{in}}\\)</p>"},{"location":"phy/pset1/","title":"PSET1","text":"<p>\\newpage</p>"},{"location":"phy/pset1/#pset1","title":"Pset1","text":"<p>Name: Divy Chandra</p> <p>Cohort: SC06</p> <p>Student ID: 1005246</p>"},{"location":"phy/pset1/#problem-1","title":"Problem 1","text":"<p>First Law: \\(\\dot{E}_{sys} = \\dot{Q}_{in} - \\dot{Q}_{out} + \\dot{W}_{in} - \\dot{W}_{out} + \\Delta \\dot{E}_{flow}\\)</p> <p>In the given problem,</p> <p>\\(\\dot{Q}_{in} = \\dot{Q}_{H}, \\;\\;\\;\\; \\dot{Q}_{out} = \\dot{Q}_{C}\\)</p> <p>\\(\\dot{W}_{out} = \\dot{W}, \\;\\;\\;\\; \\dot{W}_{in} = 0\\)</p> <p>\\(\\Delta \\dot{E}_{flow} = 0, \\;\\; \\dot{E}_{sys} = 0\\)</p>"},{"location":"phy/pset1/#a","title":"a)","text":"<p>\\(\\dot{E}_{sys} = (500 - 300) + (0 - 200) + 0 = 0\\)</p> <p>\\(\\color{blue}\\text{Therefore, the first law holds}\\)</p>"},{"location":"phy/pset1/#b","title":"b)","text":"<p>\\(\\dot{E}_{sys} = (400 - 120) + (0 - 280) + 0 = 0\\)</p> <p>\\(\\color{blue}\\text{Therefore, the first law holds}\\)</p>"},{"location":"phy/pset1/#c","title":"c)","text":"<p>\\(\\dot{E}_{sys} = (650 - 500) + (0 - 300) + 0 = -150 \\neq 0\\)</p> <p>\\(\\color{blue}\\text{Therefore, the first law does not hold}\\)</p>"},{"location":"phy/pset1/#d","title":"d)","text":"<p>\\(\\dot{E}_{sys} = (200 - 800) + (0 - 600) + 0 = -1200 \\neq 0\\)</p> <p>\\(\\color{blue}\\text{Therefore, the first law does not hold}\\)</p> <p>\\newpage</p>"},{"location":"phy/pset1/#problem-2","title":"Problem 2","text":"<p>In the given problem,</p> <p>\\(\\kappa_A = 20 \\; W/m.K, \\;\\;\\;\\;\\; L_A = 0.30 m\\)</p> <p>\\(\\kappa_B = \\; ? \\; W/m.K, \\;\\;\\;\\;\\;\\; L_B = 0.15 m\\)</p> <p>\\(\\kappa_C = 50 \\; W/m.K, \\;\\;\\;\\; L_C = 0.15 m\\)</p> <p>\\(T_0 = 800^{\\circ}C, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; T_1 = 600^{\\circ}C, \\;\\;\\;\\;\\;\\; T_4 = 20^{\\circ}C\\)</p> <p>\\(h = 25 \\; W/m^2 . K, \\;\\;\\;\\; A = 2 m^2\\)</p>"},{"location":"phy/pset1/#a_1","title":"a)","text":""},{"location":"phy/pset1/#b_1","title":"b)","text":"<p>\\(\\dot{Q} = h A (T_h - T_c) = 25 \\times 2 (800 - 600) = 10,000 W\\)</p> <p>\\(R_A = \\cfrac{L_A}{\\kappa_A A} = \\cfrac{0.3}{20 \\times 2} = 0.0075 K/W\\)</p> <p>\\(R_B = \\cfrac{L_B}{\\kappa_B A} = \\cfrac{0.15}{\\kappa_B \\times 2} = \\cfrac{0.075}{\\kappa_B}K/W\\)</p> <p>\\(R_C = \\cfrac{L_C}{\\kappa_C A} = \\cfrac{0.15}{50 \\times 2} = 0.0015 K/W\\)</p> <p>\\(R_{conv} = \\cfrac{1}{h A} = \\cfrac{1}{25 \\times 2} = 0.02 K/W\\)</p> <p>\\(R_{total, condution} = R_A+R_B+R_C = (0.009 + \\cfrac{0.075}{\\kappa_B})K/W\\)</p> <p>\\(\\dot{Q} = \\cfrac{\\Delta T}{R_{total, conduction}}\\)</p> <p>\\(10,000 = \\cfrac{600-20}{0.009 + \\cfrac{0.075}{\\kappa_B}}\\)</p> <p>On solving this equation, \\(\\color{blue}\\kappa_B = 1.53 W/m.K\\)</p>"},{"location":"phy/pset1/#c_1","title":"c)","text":"<p>\\(R_{total} = R_{conv}+R_A+R_B+R_C = 0.02 + (0.009 + \\cfrac{0.075}{1.53})K/W = 0.078K/W\\)</p> <p>\\(\\color{blue}R_{total} = 0.078K/W\\)</p> <p>\\newpage</p>"},{"location":"phy/pset1/#problem-3","title":"Problem 3","text":"<p>\\(T_1 = 1400K, \\;\\;\\;\\; P_1 = 20 \\; bar\\)</p> <p>\\(T_2 = 1100K, \\;\\;\\;\\; P_2 = 5 \\; bar\\)</p> <p>\\(T_3 = \\; ? \\; K, \\;\\;\\;\\; P_3 = 4.5 \\; bar\\)</p> <p>\\(T_4 = 980K, \\;\\;\\;\\; P_4 = 1 \\; bar\\)</p> <p>\\(T_5 = 1480K, \\;\\;\\;\\; P_5 = 1.35 \\; bar, \\;\\;\\;\\; m_5 = 1200 kg/min\\)</p> <p>\\(T_6 = 1200K, \\;\\;\\;\\; P_6 = 1 \\; bar\\)</p>"},{"location":"phy/pset1/#a_2","title":"a)","text":"<p>In the given problem, for the state going from 5 to 6:</p> <p>\\(\\dot{E}_{sys} = \\Delta \\dot{Q} + \\Delta \\dot{W} + \\Delta \\dot{E}_{flow}\\)</p> <p>\\(\\dot{E}_{sys} = 0 W, \\;\\;\\;\\; \\Delta \\dot{Q} = \\Delta \\dot{Q}_{5, 6}, \\;\\;\\;\\; \\Delta \\dot{W} = 0 W, \\;\\;\\;\\; \\dot{E}_{flow} = \\dot{m}(h_5 - h_6)\\)</p> <p>\\(\\dot{m} = 20 kg/s, \\;\\;\\;\\; h_5 = 1611.79 kJ/kg. K, \\;\\;\\;\\; h_6 = 1277.79 kJ/kg. K\\)</p> <p>\\(0 = \\Delta \\dot{Q}_{5, 6} + 0 + 20(1611.79 - 1277.79)\\)</p> <p>\\(\\Delta \\dot{Q}_{5, 6} = -6680 kW\\)</p> <p>In the given problem, for the state going from 1 to 2:</p> <p>\\(\\dot{E}_{sys} = \\Delta \\dot{Q} + \\Delta \\dot{W} + \\Delta \\dot{E}_{flow}\\)</p> <p>\\(\\dot{E}_{sys} = 0 W, \\;\\;\\;\\; \\Delta \\dot{Q} = 0 W, \\;\\;\\;\\; \\Delta \\dot{W} = -10,000 KW, \\;\\;\\;\\; \\dot{E}_{flow} = m(h_1 - h_2)\\)</p> <p>\\(h_1 = 1515.42 kJ/kg. K, \\;\\;\\;\\; h_2 = 1161.07 kJ/kg. K\\)</p> <p>\\(0 = 0 - 10000 + m(1515.42 - 1161.07)\\)</p> <p>\\(m = 28.22\\)</p> <p>In the given problem, for the state going from 2 to 3:</p> <p>\\(\\dot{E}_{sys} = \\Delta \\dot{Q} + \\Delta \\dot{W} + \\Delta \\dot{E}_{flow}\\)</p> <p>\\(\\dot{E}_{sys} = 0, \\;\\;\\;\\; \\Delta \\dot{Q} = \\Delta \\dot{Q}_{5, 6} = 6680, \\;\\;\\;\\; \\Delta \\dot{W} = 0, \\;\\;\\;\\; \\dot{E}_{flow} = 28.22(h_2 - h_3)\\)</p> <p>\\(h_2 = 1161.07 kJ/kg. K\\)</p> <p>\\(0 = 6680 + 28.22(1161.07 - h_3)\\)</p> <p>\\(h_3 = 1397.78\\)</p> <p>\\(=&gt; \\color{blue}T_3 = 1301.52 K\\)</p>"},{"location":"phy/pset1/#b_2","title":"b)","text":"<p>In the given problem, for the state going from 3 to 4:</p> <p>\\(\\dot{E}_{sys} = \\Delta \\dot{Q} + \\Delta \\dot{W} + \\Delta \\dot{E}_{flow}\\)</p> <p>\\(\\dot{E}_{sys} = 0, \\;\\;\\;\\; \\Delta \\dot{Q} = 0, \\;\\;\\;\\; \\Delta \\dot{W} = 0, \\;\\;\\;\\; \\dot{E}_{flow} = 28.22(h_3 - h_4)\\)</p> <p>\\(h_3 = 1397.78 kJ/kg. K, h_4 = 1023.25 kJ/kg. K\\)</p> <p>\\(0 = 0 + \\Delta \\dot{W} + 28.22(1397.78 - 1023.25)\\)</p> <p>\\(\\color{blue}\\dot{W}_{out} = 10569.24 kW\\)</p>"},{"location":"phy/pset2/","title":"PSET2","text":"<p>\\newpage</p>"},{"location":"phy/pset2/#pset2","title":"Pset2","text":"<p>Name: Divy Chandra</p> <p>Cohort: SC06</p> <p>Student ID: 1005246</p>"},{"location":"phy/pset2/#problem-1","title":"Problem 1","text":""},{"location":"phy/pset2/#a","title":"a)","text":"<p>From Pset 1 Q3:</p> <p>\\(\\Delta \\dot{Q}_{5, 6} = -6680 \\; kW, \\;\\;\\;\\; \\Delta \\dot{W}_{5, 6} = 0 \\; W\\)</p> <p>\\(\\Delta \\dot{Q}_{2, 3} = 6680 \\; kW, \\;\\;\\;\\;\\;\\;\\; \\Delta \\dot{W}_{2, 3} = 0 \\; W\\)</p> <p>\\(\\Delta \\dot{Q}_{1, 2} = 0 \\; kW, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\Delta \\dot{W}_{1, 2} = -10,000 \\; kW\\)</p> <p>\\(\\Delta \\dot{Q}_{3, 4} = 0 \\; kW, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\Delta \\dot{W}_{3, 4} = 10569.24 \\; kW\\)</p> <p>Using the Entropy balance for all the above stages, one by one: \\(\\cfrac{dS_{sys}}{dt} = \\cfrac{\\dot{Q}_{in}}{T_{in}} - \\cfrac{\\dot{Q}_{out}}{T_{out}} + \\dot{m}(s_i - s_e) + \\dot{\\sigma}_{gen}\\)</p> <p>For the state going from 5 to 6:</p> <p>\\(\\dot{Q}_{in} = 0 W, \\;\\;\\;\\; \\dot{Q}_{out} = 0 kW\\)</p> <p>\\(\\dot{T}_{in} = 1480 K, \\;\\;\\;\\; \\dot{T}_{out} = 1200 K\\)</p> <p>\\(s_5^{\\circ} = 3.42892 \\; kJ/kg.K \\;\\;\\;\\; s_6^{\\circ} = 3.17888 \\; kJ/kg.K\\)</p> <p>After applying the pressure correction for specific entropy:</p> <p>\\(s_5 = 3.3428 \\; kJ/kg.K \\;\\;\\;\\; s_6 = 3.17888 \\; kJ/kg.K\\)</p> <p>\\(\\dot{m} = 20 kg/s\\)</p> <p>\\(0 = 20(3.3428 - 3.17888) + \\dot{\\sigma}_{gen}\\)</p> <p>\\(\\color{purple}\\dot{\\sigma}_{gen} = -3.28 \\; kJ/s.K\\)</p> <p>(even though this value is negative, the total entropy generation for the heat exchanger is positive)</p> <p>For the state going from 2 to 3:</p> <p>\\(\\dot{Q}_{in} = 0 kW, \\;\\;\\;\\; \\dot{Q}_{out} = 0 kW\\)</p> <p>\\(\\dot{T}_{in} = 1100 K, \\;\\;\\;\\; \\dot{T}_{out} = 1301.52 K\\)</p> <p>\\(s_2^{\\circ} = 3.07732 \\; kJ/kg.K \\;\\;\\;\\; s_3^{\\circ} = 3.2748294 \\; kJ/kg.K\\)</p> <p>After applying the pressure correction for specific entropy:</p> <p>\\(s_2 = 2.6154 \\; kJ/kg.K \\;\\;\\;\\; s_3 = 2.8432 \\; kJ/kg.K\\)</p> <p>\\(\\dot{m} = 28.22 kg/s\\)</p> <p>\\(0 = 28.22(2.6154 - 2.8432) + \\dot{\\sigma}_{gen}\\)</p> <p>\\(\\color{purple}\\dot{\\sigma}_{gen} = 6.43 \\; kJ/s.K\\)</p> <p>Total entropy generated for the heat exchanger:</p> <p>\\(\\color{purple}\\dot{\\sigma}_{gen} = 6.43 - 3.28 = 3.15 kJ/s.K\\)</p> <p>For Turbine 1 (state 1 to 2):</p> <p>\\(\\dot{Q}_{in} = 0 W, \\;\\;\\;\\; \\dot{Q}_{out} = 0 kW\\)</p> <p>\\(\\dot{T}_{in} = 1400 K, \\;\\;\\;\\; \\dot{T}_{out} = 1100 K\\)</p> <p>\\(s_1^{\\circ} = 3.36200 \\; kJ/kg.K \\;\\;\\;\\; s_2^{\\circ} = 3.07732 \\; kJ/kg.K\\)</p> <p>After applying the pressure correction for specific entropy:</p> <p>\\(s_1 = 2.5022 \\; kJ/kg.K \\;\\;\\;\\; s_2 = 2.6154 \\; kJ/kg.K\\)</p> <p>\\(\\dot{m} = 28.22 kg/s\\)</p> <p>\\(0 = \\cfrac{0}{1400} - \\cfrac{0}{1100} + 28.22(2.5022 - 2.6154) + \\dot{\\sigma}_{gen}\\)</p> <p>\\(\\color{purple}\\dot{\\sigma}_{gen} = 3.19 kJ/s.K\\)</p> <p>For Turbine 2 (state 3 to 4):</p> <p>\\(\\dot{Q}_{in} = 0 W, \\;\\;\\;\\; \\dot{Q}_{out} = 0 kW\\)</p> <p>\\(\\dot{T}_{in} = 1301.52 K, \\;\\;\\;\\; \\dot{T}_{out} = 980 K\\)</p> <p>\\(s_3^{\\circ} = 3.2748294 \\; kJ/kg.K \\;\\;\\;\\; s_4^{\\circ} = 2.94468 \\; kJ/kg.K\\)</p> <p>After applying the pressure correction for specific entropy:</p> <p>\\(s_3 = 2.8432 \\; kJ/kg.K \\;\\;\\;\\; s_4 = 2.94468 \\; kJ/kg.K\\)</p> <p>\\(\\dot{m} = 28.22 kg/s\\)</p> <p>\\(0 = \\cfrac{0}{1301.52} - \\cfrac{0}{980} + 28.22(2.8432 - 2.94468) + \\dot{\\sigma}_{gen}\\)</p> <p>\\(\\color{purple}\\dot{\\sigma}_{gen} = 2.86 kJ/s.K\\)</p> <p>\\newpage</p> <p>\\(\\color{blue}\\text{Entropy Generated from the heat exchanger (he)} = \\dot{\\sigma}_{gen, he} = 3.15 kJ/s.K\\)</p> <p>\\(\\color{blue}\\text{Entropy Generated from Turbine 1 (t1)} \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; = \\dot{\\sigma}_{gen, t1} = 3.19 kJ/s.K\\)</p> <p>\\(\\color{blue}\\text{Entropy Generated from Turbine 2 (t2)} \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; = \\dot{\\sigma}_{gen, t2} = 2.86 kJ/s.K\\)</p>"},{"location":"phy/pset2/#b","title":"b)","text":"<p>The most inefficient component is the one that generates the most entropy. In decreasing order of amount of entropy generated (going from least efficient to most efficient), the components are:</p> <p>\\(\\color{blue}\\text{Turbine 1, Heat Exchanger, Turbine 2}\\)</p> <p>\\newpage</p>"},{"location":"phy/pset2/#problem-2","title":"Problem 2","text":"<p>\\(T_{out} = 0^{\\circ}C, \\;\\;\\;\\; T_{wall, out} = 5^{\\circ}C, \\;\\;\\;\\; T_{wall, in} = 20^{\\circ}C, \\;\\;\\;\\; T_{in} = 27^{\\circ}C\\)</p> <p>\\(L = 0.3 m, \\;\\;\\;\\; A = 30 m^2, \\;\\;\\;\\; \\dot{Q} = 1035 W\\)</p>"},{"location":"phy/pset2/#a_1","title":"a)","text":"<p>\\(\\Delta\\dot{X}_{work} = 0 kW\\)</p> <p>\\(\\dot{X}_{heat, in} = (1 - \\cfrac{T_0}{T})\\dot{Q} = (1 - \\cfrac{273}{293})1035 = 70.65 kW\\)</p> <p>\\(\\dot{X}_{heat, in} = (1 - \\cfrac{T_0}{T})\\dot{Q} = (1 - \\cfrac{273}{278})1035 = 18.62 kW\\)</p> <p>\\(\\Delta\\dot{X} = \\Delta\\dot{X}_{heat} + \\Delta\\dot{X}_{work} - \\dot{X}_{destroyed}\\)</p> <p>\\(0 = 70.65 - 18.62 - \\dot{X}_{destroyed}\\)</p> <p>\\(\\color{blue}\\dot{X}_{destroyed} = 52.03 kW\\)</p>"},{"location":"phy/pset2/#b_1","title":"b)","text":"<p>\\(\\Delta\\dot{X}_{work} = 0 kW\\)</p> <p>\\(\\Delta\\dot{X}_{heat} = (1 - \\cfrac{T_0}{T})\\dot{Q} = (1 - \\cfrac{273}{300})1035 = 93.15 kW\\)</p> <p>(There is no \\(X_{out}\\) here, only \\(X_{in}\\))</p> <p>\\(\\Delta\\dot{X} = \\Delta\\dot{X}_{heat} + \\Delta\\dot{X}_{work} - \\dot{X}_{destroyed}\\)</p> <p>\\(0 = 93.15 - \\dot{X}_{destroyed}\\)</p> <p>\\(\\color{blue}\\dot{X}_{destroyed} = 93.15 kW\\)</p>"},{"location":"phy/pset2/#c","title":"c)","text":"<p>The exergy destroyed in the entire process is more than just the exergy destroyed during the conduction through the wall because it includes two additional convection processes that contribute to the total exergy destroyed which are not taken into account for heat transfer through just the wall. Thermal resistivity diagram:</p> <p></p> <p>\\newpage</p>"},{"location":"phy/pset2/#problem-3","title":"Problem 3","text":"<p>From Problem 1</p> <p>\\(\\dot{\\sigma}_{gen, he} = 3.15 = kJ/s.K\\)</p> <p>\\(\\dot{\\sigma}_{gen, t1} = 3.19 kJ/s.K\\)</p> <p>\\(\\dot{\\sigma}_{gen, t2} = 2.86 kJ/s.K\\)</p>"},{"location":"phy/pset2/#a_2","title":"a)","text":"<p>\\(\\dot{X}_{destroyed, he} = T_0 \\dot{\\sigma}_{gen, he} = 300 \\times 3.15 = 945 \\; kW\\)</p> <p>\\(\\dot{X}_{destroyed, t1} = T_0 \\dot{\\sigma}_{gen, t1} = 300 \\times 3.19 = 957 \\; kW\\)</p> <p>\\(\\dot{X}_{destroyed, t2} = T_0 \\dot{\\sigma}_{gen, t2} = 300 \\times 2.86 = 858 \\; kW\\)</p> <p>\\(\\color{blue}\\dot{X}_{destroyed, he} = 945 \\; kW\\)</p> <p>\\(\\color{blue}\\dot{X}_{destroyed, t1} = 957 \\; kW\\)</p> <p>\\(\\color{blue}\\dot{X}_{destroyed, t2} = 858 \\; kW\\)</p>"},{"location":"phy/pset2/#b_2","title":"b)","text":"<p>\\(\\epsilon = 1 - \\cfrac{\\dot{X}_{destroyed}}{\\dot{X}_{supplied}}\\)</p> <p>\\(X_{supplied} = m(\\psi_{in} - \\psi_{out})\\)</p> <p>\\(X_{supplied} = m((h_{in} - h_{out}) - T_0(s_{in} - s_{out}))\\)</p> <p>For Turbine 1 (The state going from 1 to 2):</p> <p>\\(s_1^{\\circ} = 3.36200 \\; kJ/kg.K \\;\\;\\;\\; s_2^{\\circ} = 3.07732 \\; kJ/kg.K\\)</p> <p>After applying the pressure correction for specific entropy:</p> <p>\\(s_1 = 2.5022 \\; kJ/kg.K \\;\\;\\;\\; s_2 = 2.6154 \\; kJ/kg.K\\)</p> <p>\\(h_1 = 1515.42 \\; kJ/kg \\;\\;\\;\\; h_2 = 1161.07 \\; kJ/kg\\)</p> <p>\\(X_{supplied} = 28.22((1515.42 - 1161.07) - 300(2.5022 - 2.6154)) = 10958.1082 \\; kW\\)</p> <p>\\(\\epsilon_1 = 1 - \\cfrac{957}{10958.1082} = 0.91\\)</p> <p>\\(\\color{purple}\\epsilon_1 = 0.91\\)</p> <p>For Turbine 2 (The state going from 3 to 4):</p> <p>\\(s_3^{\\circ} = 3.2748294 \\; kJ/kg.K \\;\\;\\;\\; s_4^{\\circ} = 2.94468 \\; kJ/kg.K\\)</p> <p>After applying the pressure correction for specific entropy:</p> <p>\\(s_3 = 2.8432 \\; kJ/kg.K \\;\\;\\;\\; s_4 = 2.94468 \\; kJ/kg.K\\)</p> <p>\\(h_3 = 1397.77804 \\; kJ/kg \\;\\;\\;\\; h_4 = 1023.25 \\; kJ/kg\\)</p> <p>\\(X_{supplied} = 28.22((1397.77804 - 1023.25) - 300(2.8432 - 2.94468)) = 11428.31 \\; kW\\)</p> <p>\\(\\epsilon_2 = 1 - \\cfrac{858}{11428.31} = 0.92\\)</p> <p>\\(\\color{purple}\\epsilon_2 = 0.92\\)</p> <p>\\(\\color{blue} \\text{Efficiency of Turbine 1} = \\epsilon_1 = 0.91\\)</p> <p>\\(\\color{blue} \\text{Efficiency of Turbine 2} = \\epsilon_2 = 0.92\\)</p>"},{"location":"phy/pset2/#c_1","title":"c)","text":"<p>For Heat Exchanger (The state going from 5 to 6):</p> <p>\\(s_5^{\\circ} = 3.42892 \\; kJ/kg.K \\;\\;\\;\\; s_6^{\\circ} = 3.17888 \\; kJ/kg.K\\)</p> <p>After applying the pressure correction for specific entropy:</p> <p>\\(s_5 = 3.3428 \\; kJ/kg.K \\;\\;\\;\\; s_6 = 3.17888 \\; kJ/kg.K\\)</p> <p>\\(h_5 = 1611.79 \\; kJ/kg \\;\\;\\;\\; h_6 = 1277.79 \\; kJ/kg\\)</p> <p>\\(X_{supplied} = 20((1611.79 - 1277.79) - 300(3.3428 - 3.17888)) = 5696.48 \\; kW\\)</p> <p>\\(\\epsilon_{he} = 1 - \\cfrac{945}{5696.48} = 0.83\\)</p> <p>\\(\\color{blue} \\text{Efficiency of the heat exchanger} = \\epsilon_{he} = 0.83\\)</p>"},{"location":"phy/pset2/#d","title":"d)","text":"<p>For the overall system,</p> <p>Total \\(X_{destroyed} = 945 + 958 + 858 = 2761 \\; kW\\)</p> <p>\\(X_{supplied} = X_{supplied, process} + X_{supplied, he} \\; kW\\)</p> <p>\\(X_{supplied} = \\dot{m}(h_1 - h_4 - T_0(s_1 - s_4)) + X_{supplied, he} \\; kW\\)</p> <p>\\(X_{supplied} = 28.22(1515.42 - 1023.25 - 300(2.5022 - 2.94468)) + 5696.48 = 23331.55 \\; kW\\)</p> <p>\\(\\epsilon = 1 - \\cfrac{2761}{23331.55} = 0.88\\)</p> <p>\\(\\color{blue} \\text{Efficiency} = \\epsilon = 0.88\\)</p>"},{"location":"phy/pset3/","title":"PSET3","text":"<p>\\newpage</p>"},{"location":"phy/pset3/#pset3","title":"Pset3","text":"<p>Name: Divy Chandra</p> <p>Cohort: SC06</p> <p>Student ID: 1005246</p>"},{"location":"phy/pset3/#problem-1","title":"Problem 1","text":""},{"location":"phy/pset3/#a","title":"a)","text":"<p>\\(e = \\cfrac{V.n.q}{m}\\)</p> <p>\\(e = \\cfrac{1.72 \\times 53.6 \\times 3600}{0.1124/2 + 0.0917} = 2244024.34 \\; J/kg\\)</p>"},{"location":"phy/pset3/#b","title":"b)","text":"<p>Specific Energy \\(= \\cfrac{V.n.q}{m}\\)</p> <p>Specific Energy \\(= \\cfrac{4.8 \\times 0.7 \\times 3600}{0.105} = 115200.0 \\; J/kg\\)</p> <p>Energy Density \\(= \\cfrac{V.n.q}{v}\\)</p> <p>Energy Density \\(= \\cfrac{4.8 \\times 0.7 \\times 3600}{0.056\\times0.05\\times0.0142} = 304225352.11 \\; J/m^3\\)</p> <p>The specific energy of the actual batter is lower probably because:</p> <ol> <li>It probably does not use exactly \\(147.9g\\) of material</li> <li>The full weight of the battery used in the above calculation also probably includes the weight of the battery's casing which should really be subtracted because its not part of the active mass of the battery</li> </ol> <p>\\newpage</p>"},{"location":"phy/pset3/#problem-2","title":"Problem 2","text":""},{"location":"phy/pset3/#i-ii","title":"i) ii)","text":"<p>An LFP battery that would be good for this task can be found here and its datasheet can be found here</p>"},{"location":"phy/pset3/#iii","title":"iii)","text":"<p>This battery is \\(2.7 kg\\) lighter than the lead acid battery previously used, which is almost half the weight of the lead acid battery. Unfortunately its datasheet does not contain a Capacity Remaining vs DoD and # of Cycles characteristic curve, but the battery mentions that life cycle at 100% DoD is 2000 Cycles, which is much better than the 200 for the lead acid battery</p>"},{"location":"phy/pset3/#iv","title":"iv)","text":"<p>Another factor to consider is the size of the battery.</p> <p>This battery is \\(181 \\; mm \\times 76 \\; mm \\times 165 \\; mm\\) which is nearly the same size as the original lead acid battery. This means that the original casings built for the lead acid battery should be able to house the new battery with little to no modification.</p>"},{"location":"phy/pset4/","title":"PSET4","text":"<p>\\newpage</p>"},{"location":"phy/pset4/#pset4","title":"Pset4","text":"<p>Name: Divy Chandra</p> <p>Cohort: SC06</p> <p>Student ID: 1005246</p>"},{"location":"phy/pset4/#problem-1","title":"Problem 1","text":"<p>Two types of solar cells are:</p> <ol> <li> <p>Monocrystalline</p> <p>Advantage: They are the most efficient solar panels, with an efficiency of about (15% - 20%)</p> <p>Disadvantage: They are quite expensive</p> </li> <li> <p>Polycrystalline</p> <p>Advantage: They are cheaper and easier to produce than monocrystalline solar panels</p> <p>Disadvantage: Their efficiency is lower than that of monocrystalline cells (13% - 16%)</p> </li> </ol>"},{"location":"phy/pset4/#problem-2","title":"Problem 2","text":"<p>It is known that \\(I_o\\) (the reverse saturation current) is directly proportional to the intensity of light incident on the solar panel.</p> <p>Also note that:</p> <p>\\(I_{sc} = I_o(e^{\\cfrac{eV}{k_B T}} - 1)\\)</p> <p>\\(V_{oc} = \\cfrac{K_B T}{e} ln\\left(\\cfrac{I_{sc}}{I_o} + 1\\right)\\)</p> <p>From the first formula, we note that \\(I_{sc}\\) is proportional to the \\(I_o\\) which implies that it is also proportional to the intensity of light incident on the solar panel.</p> <p>Hence, when the light intensity is doubled, we get the new \\(I_{sc} = 300 mA\\)</p> <p>Using the first formula in the second formula, we can write:</p> <p>\\(I_{sc} = I_o(e^{\\cfrac{qV}{k_B T}} - 1)\\)</p> <p>\\(\\cfrac{I_{sc}}{I_o} = e^{\\cfrac{qV}{k_B T}} - 1\\)</p> <p>For \\(500 W/m^2\\), we have:</p> <p>\\(\\cfrac{0.15}{I_o} = e^{\\cfrac{e 0.53}{k_B T}} - 1\\)</p> <p>For \\(1000 W/m^2\\), we have:</p> <p>\\(\\cfrac{0.3}{I_o} = e^{\\cfrac{qV_{oc}}{k_B T}} - 1\\)</p> <p>Dividing the two equations:</p> <p>\\(\\cfrac{1}{2} = \\cfrac{e^{\\cfrac{q 0.53}{k_B T}} - 1}{e^{\\cfrac{qV_{oc}}{k_B T}} - 1}\\)</p> <p>\\(e^{\\cfrac{qV_{oc}}{k_B T}} - 1 = 2 \\times e^{\\cfrac{q 0.53}{k_B T}} - 2\\)</p> <p>\\(e^{\\cfrac{qV_{oc}}{k_B T}} = 2 \\times e^{\\cfrac{q 0.53}{k_B T}} - 1\\)</p> <p>Log on both sides:</p> <p>\\(\\cfrac{qV_{oc}}{k_B T} = ln\\left( 2 \\times e^{\\cfrac{q 0.53}{k_B T}} - 1 \\right)\\)</p> <p>we know that \\(q = 1.6 \\times 10^{-19} C\\) and \\(K_B T = 4.149 \\times 10^{-21} J\\). Using these values, we calculate and simplify the above expression to:</p> <p>\\(38.56 V_{oc} = 21.13\\)</p> <p>\\(\\color{blue} V_{oc} = 0.548 V\\)</p> <p>\\(\\color{blue} I_{sc} = 300 mA\\)</p> <p>\\newpage</p>"},{"location":"phy/pset4/#problem-3","title":"Problem 3","text":""},{"location":"phy/pset4/#i","title":"i)","text":"<p>From the graph above,</p> <p>\\(\\color{blue} V = 0.104681 V\\) \\(\\color{blue} I = 0.037234 A\\)</p>"},{"location":"phy/pset4/#ii","title":"ii)","text":"<p>\\(P = 0.104681 \\times 0.037234 W\\)</p> <p>\\(\\color{blue} P = 0.0039 W\\)</p>"},{"location":"phy/pset4/#iii","title":"iii)","text":"<p>\\(\\% Conversion = \\cfrac{P_{delivered}}{P_{incident}} \\times 100\\% = \\cfrac{0.0039}{1000 \\times 10^{-4}} \\times 100\\%\\)</p> <p>\\(\\color{blue} \\% Conversion = 3.9 \\%\\)</p> <p>\\newpage</p>"},{"location":"phy/pset4/#iv","title":"iv)","text":"<p>From the graph above,</p> <p>\\(\\color{blue} P_{max} = 0.0176 W\\)</p>"},{"location":"phy/pset4/#v","title":"v)","text":"<p>\\(V_{oc} = 0.62 V\\)</p> <p>\\(I_{sc} = 0.037 A\\)</p> <p>\\(FF = \\cfrac{P_{max}}{V_{oc} I_{sc}} = \\cfrac{0.0176}{0.62 \\times 0.037}\\)</p> <p>\\(\\color{blue} FF = 0.767\\)</p>"},{"location":"phy/pset4/#vi","title":"vi)","text":"<p>\\(\\eta = \\cfrac{P_{max}}{P_{in}} = {0.0176}{0.1}\\)</p> <p>\\(\\color{blue} \\eta = 0.176\\)</p>"},{"location":"phy/to_know/","title":"Important Information","text":""}]}